TCVAE_ART_30: # SigType_LatDim
  LatDim: 30 # The dimensionality of the latent variable z.
  SigType: rawART # Types of signals to train on.: ART, PLETH, II. 
  ReparaStd: 0.1 # The standard deviation value for Gaussian noise generation used in the reparametrization trick.
  Capacity_Z: 0.1 # The capacity value for controlling the Kullback-Leibler divergence (KLD) of Z.
  Capacity_TC: 0.01 # The capacity value for controlling the Kullback-Leibler divergence (KLD) of TC.
  Capacity_MI: 0.1 # The capacity value for controlling the Kullback-Leibler divergence (KLD) of MI.
  
  BatSize: 2800 # The batch size for the training
  NEpochs: 3000 # The epoch size for the training
  
  WRec: 500 # The scaling weight for the reconstruction loss.
  WZ: 0.1 # The scaling weight for the Z loss.
  WTC: 0.001 # The scaling weight for the TC loss.
  WMI: 0.001 # The scaling weight for the MI loss.
  
  MnWRec: 1 # The min weight for the reconstruction loss.
  MnWZ: 0.001 # The min weight for the Z loss.
  MnWTC: 0.00001 # The min weight for the TC loss. 
  MnWMI: 0.000001 # The min weight for the MI loss.
  
  MxWRec: 200 # The max weight for the reconstruction loss.
  MxWZ: 0.01 # The max weight for the Z loss.
  MxWTC: 0.00002 # The max weight for the TC loss.
  MxWMI: 0.000002 # The max weight for the MI loss.  
  

TCVAE_ART_50: # SigType_LatDim
  LatDim: 50 # The dimensionality of the latent variable z.
  SigType: rawART # Types of signals to train on.: ART, PLETH, II. 
  ReparaStd: 0.1 # The standard deviation value for Gaussian noise generation used in the reparametrization trick.
  Capacity_Z: 0.1 # The capacity value for controlling the Kullback-Leibler divergence (KLD) of Z.
  Capacity_TC: 0.01 # The capacity value for controlling the Kullback-Leibler divergence (KLD) of TC.
  Capacity_MI: 0.1 # The capacity value for controlling the Kullback-Leibler divergence (KLD) of MI.
  
  BatSize: 2800 # The batch size for the training
  NEpochs: 3000 # The epoch size for the training
  
  WRec: 500 # The scaling weight for the reconstruction loss.
  WZ: 0.1 # The scaling weight for the Z loss.
  WTC: 0.001 # The scaling weight for the TC loss.
  WMI: 0.001 # The scaling weight for the MI loss.
  
  MnWRec: 1 # The min weight for the reconstruction loss.
  MnWZ: 0.001 # The min weight for the Z loss.
  MnWTC: 0.00001 # The min weight for the TC loss. 
  MnWMI: 0.000001 # The min weight for the MI loss.
  
  MxWRec: 200 # The max weight for the reconstruction loss.
  MxWZ: 0.01 # The max weight for the Z loss.
  MxWTC: 0.00002 # The max weight for the TC loss.
  MxWMI: 0.000002 # The max weight for the MI loss.  


FACVAE_ART_30: # SigType_LatDim
  LatDim: 30 # The dimensionality of the latent variable z.
  SigType: rawART # Types of signals to train on.: ART, PLETH, II. 
  DiscHiddenSize: 50 # The size of the hidden nodes within the discriminator model.
  ReparaStd: 0.1 # The standard deviation value for Gaussian noise generation used in the reparametrization trick.
  Capacity_Z: 0.1 # The capacity value for controlling the Kullback-Leibler divergence (KLD) of Z.
  Capacity_TC: 0.01 # The capacity value for controlling the Kullback-Leibler divergence (KLD) of TC.
  Capacity_DTC: 0.1 # The capacity value for controlling the Kullback-Leibler divergence (KLD) of DTC.
  
  BatSize: 2800 # The batch size for the training
  NEpochs: 3000 # The epoch size for the training
  
  WRec: 500 # The scaling weight for the reconstruction loss.
  WZ: 0.1 # The scaling weight for the Z loss.
  WTC: 0.1 # The scaling weight for the TC loss.
  WDTC: 0.1 # The scaling weight for the DTC loss.
  
  MnWRec: 1 # The min weight for the reconstruction loss.
  MnWZ: 0.01 # The min weight for the Z loss.
  MnWTC: 0.01 # The min weight for the TC loss.
  MnWDTC: 0.01 # The min weight for the DTC loss.
  
  MxWRec: 500 # The max weight for the reconstruction loss.
  MxWZ: 0.08 # The max weight for the Z loss.
  MxWTC: 0.15 # The max weight for the TC loss.
  MxWDTC: 0.65 # The max weight for the DTC loss.  


FACVAE_ART_50: # SigType_LatDim
  LatDim: 50 # The dimensionality of the latent variable z.
  SigType: rawART # Types of signals to train on.: ART, PLETH, II. 
  DiscHiddenSize: 50 # The size of the hidden nodes within the discriminator model.
  ReparaStd: 0.1 # The standard deviation value for Gaussian noise generation used in the reparametrization trick.
  Capacity_Z: 0.1 # The capacity value for controlling the Kullback-Leibler divergence (KLD) of Z.
  Capacity_TC: 0.01 # The capacity value for controlling the Kullback-Leibler divergence (KLD) of TC.
  Capacity_DTC: 0.1 # The capacity value for controlling the Kullback-Leibler divergence (KLD) of DTC.
  
  BatSize: 2800 # The batch size for the training
  NEpochs: 3000 # The epoch size for the training
  
  WRec: 500 # The scaling weight for the reconstruction loss.
  WZ: 0.1 # The scaling weight for the Z loss.
  WTC: 0.1 # The scaling weight for the TC loss.
  WDTC: 0.1 # The scaling weight for the DTC loss.
  
  MnWRec: 1 # The min weight for the reconstruction loss.
  MnWZ: 0.01 # The min weight for the Z loss.
  MnWTC: 0.01 # The min weight for the TC loss.
  MnWDTC: 0.01 # The min weight for the DTC loss.
  
  MxWRec: 500 # The max weight for the reconstruction loss.
  MxWZ: 0.08 # The max weight for the Z loss.
  MxWTC: 0.15 # The max weight for the TC loss.
  MxWDTC: 0.65 # The max weight for the DTC loss.  
  

ConVAE_ART_30: # SigType_LatDim
  LatDim: 30 # The dimensionality of the latent variable z.
  SigType: rawART # Types of signals to train on.: ART, PLETH, II. 
  ReparaStd: 0.1 # The standard deviation value for Gaussian noise generation used in the reparametrization trick.
  Capacity_Z: 0.1 # The capacity value for controlling the Kullback-Leibler divergence (KLD) of Z.

  BatSize: 2800 # The batch size for the training
  NEpochs: 3000 # The epoch size for the training
  
  WRec: 50 # The scaling weight for the reconstruction loss.
  WZ: 0.002 # The scaling weight for the Z loss.
  MnWRec: 1 # The min weight for the reconstruction loss.
  MnWZ: 0.001 # The min weight for the Z loss.
  MxWRec: 100 # The max weight for the reconstruction loss.
  MxWZ: 0.005 # The max weight for the Z loss.
  

ConVAE_ART_50: # SigType_LatDim
  LatDim: 50 # The dimensionality of the latent variable z.
  SigType: rawART # Types of signals to train on.: ART, PLETH, II. 
  ReparaStd: 0.1 # The standard deviation value for Gaussian noise generation used in the reparametrization trick.
  Capacity_Z: 0.1 # The capacity value for controlling the Kullback-Leibler divergence (KLD) of Z.

  BatSize: 2800 # The batch size for the training
  NEpochs: 3000 # The epoch size for the training
  
  WRec: 50 # The scaling weight for the reconstruction loss.
  WZ: 0.002 # The scaling weight for the Z loss.
  MnWRec: 1 # The min weight for the reconstruction loss.
  MnWZ: 0.001 # The min weight for the Z loss.
  MxWRec: 100 # The max weight for the reconstruction loss.
  MxWZ: 0.005 # The max weight for the Z loss.
  
  
BaseVAE_ART_50: # SigType_LatDim
  LatDim: 50 # The dimensionality of the latent variable z.
  SigType: rawART # Types of signals to train on.: ART, PLETH, II. 
  ReparaStd: 0.1 # The standard deviation value for Gaussian noise generation used in the reparametrization trick.
  Capacity_Z: 0.1 # The capacity value for controlling the Kullback-Leibler divergence (KLD) of Z.

  BatSize: 2800 # The batch size for the training
  NEpochs: 3000 # The epoch size for the training
  
  WRec: 50 # The scaling weight for the reconstruction loss.
  WZ: 0.01 # The scaling weight for the Z loss.
  MnWRec: 1 # The min weight for the reconstruction loss.
  MnWZ: 0.001 # The min weight for the Z loss.
  MxWRec: 100 # The max weight for the reconstruction loss.
  MxWZ: 0.01 # The max weight for the Z loss.
  
  
BaseVAE_ART_30: # SigType_LatDim
  LatDim: 30 # The dimensionality of the latent variable z.
  SigType: rawART # Types of signals to train on.: ART, PLETH, II. 
  ReparaStd: 0.1 # The standard deviation value for Gaussian noise generation used in the reparametrization trick.
  Capacity_Z: 0.1 # The capacity value for controlling the Kullback-Leibler divergence (KLD) of Z.

  BatSize: 2800 # The batch size for the training
  NEpochs: 3000 # The epoch size for the training
  
  WRec: 50 # The scaling weight for the reconstruction loss.
  WZ: 0.01 # The scaling weight for the Z loss.
  MnWRec: 1 # The min weight for the reconstruction loss.
  MnWZ: 0.001 # The min weight for the Z loss.
  MxWRec: 100 # The max weight for the reconstruction loss.
  MxWZ: 0.01 # The max weight for the Z loss.
  
