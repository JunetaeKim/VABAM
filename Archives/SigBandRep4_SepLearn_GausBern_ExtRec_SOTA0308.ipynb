{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Input, GRU, Dense, Masking, Reshape, Flatten, RepeatVector, TimeDistributed, Bidirectional, Activation, GaussianNoise, Lambda, LSTM\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from Models.FeatExtModels_NoKaiser import *\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = np.load('./Data/AsanTRSet.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Env setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './Results/'\n",
    "if not os.path.exists(save_path):\n",
    "    os.mkdir(save_path)\n",
    "    \n",
    "### Model checkpoint\n",
    "ModelSaveSameName = save_path+'SigBandRepModel_ExtRec.hdf5'\n",
    "ModelSave = ModelCheckpoint(filepath=ModelSaveSameName, monitor='val_mse', verbose=1, save_best_only=True )\n",
    "\n",
    "### Model Early stop\n",
    "EarlyStop = EarlyStopping(monitor='val_loss', patience=500)\n",
    "\n",
    "LatDim = 3\n",
    "SigDim = DATA.shape[1]\n",
    "MaskingRate = 0.02\n",
    "NoiseStd = 0.002\n",
    "MaskStd = 0.1\n",
    "ReparaStd = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "class RelLossWeight(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, LossName1, LossName2, BetaName1, BetaName2, verbose=1):\n",
    "                \n",
    "        self.LossName1 = LossName1\n",
    "        self.LossName2 = LossName2\n",
    "        self.BetaName1 = BetaName1\n",
    "        self.BetaName2 = BetaName2\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        Loss1 = logs[self.LossName1] \n",
    "        Loss2 = logs[self.LossName2] \n",
    "        \n",
    "        Beta1_idx = [num for num, i in enumerate(self.model.variables) if self.BetaName1 in i.name][0]\n",
    "        Beta2_idx = [num for num, i in enumerate(self.model.variables) if self.BetaName2 in i.name][0]\n",
    "        \n",
    "        self.model.variables[Beta1_idx].assign(Loss1/Loss2)\n",
    "        self.model.variables[Beta2_idx].assign(Loss2/Loss1)   \n",
    "\n",
    "        if self.verbose==1:\n",
    "            print(self.BetaName1+' : ', self.model.variables[Beta1_idx])\n",
    "            print(self.BetaName2+' : ', self.model.variables[Beta2_idx])        \n",
    " \n",
    "\n",
    "# Define the KL annealing callback function\n",
    "class KLCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, TargetLossName, Threshold, MaxBeta, BetaName, AnnealEpoch=100):\n",
    "        self.TargetLossName = TargetLossName\n",
    "        self.Threshold = Threshold\n",
    "        self.BetaName = BetaName\n",
    "        self.MaxBeta = MaxBeta\n",
    "        self.AnnealStart = 0\n",
    "        self.AnnealEpoch = AnnealEpoch\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        TargetLoss = logs['val_'+self.TargetLossName]\n",
    "        \n",
    "        if TargetLoss > self.Threshold:\n",
    "            \n",
    "            self.AnnealStart = 0\n",
    "            K.set_value(self.model.get_layer(self.BetaName).variables[0], 0.)\n",
    "        else: \n",
    "            self.AnnealStart += 1\n",
    "            Beta = (self.AnnealStart) / self.AnnealEpoch * self.MaxBeta\n",
    "            K.set_value(self.model.get_layer(self.BetaName).variables[0], Beta)\n",
    "        \n",
    "        print(self.model.get_layer(self.BetaName).variables[0])\n",
    "'''\n",
    "\n",
    "'''\n",
    "class KLAnneal(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, TargetLossName, Threshold,  BetaName, MaxBeta=0.1, MinBeta=1e-5, AnnealEpoch=100, UnderLimit=0., verbose=1):\n",
    "        \n",
    "        if type(TargetLossName) != list:\n",
    "            TargetLossName = [TargetLossName]\n",
    "        \n",
    "        self.TargetLossName = TargetLossName\n",
    "        self.Threshold = Threshold\n",
    "        self.BetaName = BetaName\n",
    "        self.AnnealIdx = 0\n",
    "        self.verbose = verbose \n",
    "        self.Beta =  np.concatenate([np.array([UnderLimit]), np.linspace(start=MinBeta, stop=MaxBeta, num=AnnealEpoch )])\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        TargetLoss = max([logs[i] for i in self.TargetLossName]) \n",
    "        \n",
    "        if TargetLoss > self.Threshold:\n",
    "            \n",
    "            #self.AnnealIdx -= 1\n",
    "            #self.AnnealIdx = np.maximum(self.AnnealIdx, 0)\n",
    "            K.set_value(self.model.get_layer(self.BetaName).variables[0], self.Beta[self.AnnealIdx])\n",
    "        else: \n",
    "            self.AnnealIdx += 1\n",
    "            self.AnnealIdx = np.minimum(self.AnnealIdx, len(self.Beta)-1)\n",
    "            K.set_value(self.model.get_layer(self.BetaName).variables[0], self.Beta[self.AnnealIdx])\n",
    "        \n",
    "        if self.verbose==1:\n",
    "            print(self.BetaName+' : ' ,self.model.get_layer(self.BetaName).variables[0].numpy())\n",
    "        elif self.verbose==2:\n",
    "            print('TargetLoss : ', TargetLoss)\n",
    "            print(self.BetaName+' : ' ,self.model.get_layer(self.BetaName).variables[0].numpy())\n",
    "'''\n",
    "\n",
    "'''\n",
    "class RelLossWeight(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, LossName1, LossName2, Beta1, Beta2, WeightB1 =1., WeightB2 =1., BetaName1 ='Beta1' , BetaName2 ='Beta2' , verbose=1):\n",
    "                \n",
    "        self.LossName1 = LossName1\n",
    "        self.LossName2 = LossName2\n",
    "        self.Beta1 = Beta1\n",
    "        self.Beta2 = Beta2\n",
    "        self.BetaName1 = BetaName1\n",
    "        self.BetaName2 = BetaName2\n",
    "        self.verbose = verbose\n",
    "        self.WeightB1 = WeightB1\n",
    "        self.WeightB2 = WeightB2\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        Loss1 = logs[self.LossName1] \n",
    "        Loss2 = logs[self.LossName2] \n",
    "        \n",
    "        Beta1 = tf.maximum(Loss1/Loss2, 1.) * self.WeightB1\n",
    "        Beta2 = tf.maximum(Loss2/Loss1, 1.) * self.WeightB2\n",
    "        \n",
    "        self.Beta1.assign(Beta1)\n",
    "        self.Beta2.assign(Beta2)   \n",
    "\n",
    "        if self.verbose==1:\n",
    "            print(self.BetaName1+' : ', self.Beta1.numpy())\n",
    "            print(self.BetaName2+' : ', self.Beta2.numpy())   \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "class KLAnneal(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, TargetLossName, Threshold,  Beta, BetaName ='Beta', MaxBeta=0.1, MinBeta=1e-5, AnnealEpoch=100, UnderLimit=0., verbose=1):\n",
    "        \n",
    "        if type(TargetLossName) != list:\n",
    "            TargetLossName = [TargetLossName]\n",
    "        \n",
    "        self.TargetLossName = TargetLossName\n",
    "        self.Threshold = Threshold\n",
    "        self.Beta = Beta\n",
    "        self.BetaName = BetaName\n",
    "        self.AnnealIdx = 0\n",
    "        self.verbose = verbose \n",
    "        self.BetaValue =  np.concatenate([np.array([UnderLimit]), np.linspace(start=MinBeta, stop=MaxBeta, num=AnnealEpoch )])\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        TargetLoss = max([logs[i] for i in self.TargetLossName]) \n",
    "        \n",
    "        if TargetLoss > self.Threshold:\n",
    "            \n",
    "            #self.AnnealIdx -= 1\n",
    "            #self.AnnealIdx = np.maximum(self.AnnealIdx, 0)\n",
    "            self.Beta.assign(self.BetaValue[self.AnnealIdx])\n",
    "        else: \n",
    "            self.AnnealIdx += 1\n",
    "            self.AnnealIdx = np.minimum(self.AnnealIdx, len(self.BetaValue)-1)\n",
    "            self.Beta.assign(self.BetaValue[self.AnnealIdx])\n",
    "        \n",
    "        if self.verbose==1:\n",
    "            print(self.BetaName+' : ' ,self.Beta.numpy())\n",
    "        elif self.verbose==2:\n",
    "            print('TargetLoss : ', TargetLoss)\n",
    "            print(self.BetaName+' : ' ,self.Beta.numpy())\n",
    "            \n",
    "            \n",
    "       \n",
    "class RelLossWeight(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, BetaList, BetaWeight, MinLimit , MaxLimit , verbose=1):\n",
    "                \n",
    "        self.BetaList = BetaList\n",
    "        self.BetaWeight = BetaWeight\n",
    "        self.MinLimit = MinLimit\n",
    "        self.MaxLimit = MaxLimit\n",
    "        self.verbose = verbose\n",
    "\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        Losses = np.array([logs[i] for i in self.BetaList.keys()])\n",
    "        Losses = np.maximum(1e-7, Losses)\n",
    "        RelWeights = Losses / np.min(Losses)\n",
    "        RelWeights = {LossName:RelWeights[num] for num, LossName in enumerate (self.BetaList.keys())}\n",
    "\n",
    "        for name, beta in self.BetaList.items():\n",
    "            \n",
    "            Value = np.clip(RelWeights[name] * self.BetaWeight[name], self.MinLimit[name], self.MaxLimit[name])\n",
    "            beta.assign(Value)\n",
    "\n",
    "        if self.verbose==1:\n",
    "            print(RelWeights)\n",
    "            for key, beta in self.BetaList.items():\n",
    "                print(key, ': ', beta.numpy())\n",
    "                \n",
    "RelLossDic = {'val_mse':'Beta_Rec', 'val_FeatRecLoss':'Beta_Feat', 'val_kl_Loss_Z':'Beta_Z', 'val_kl_Loss_FC':'Beta_Fc'}\n",
    "WeightDic = {'val_mse':10., 'val_FeatRecLoss':100., 'val_kl_Loss_Z':1., 'val_kl_Loss_FC':1.}\n",
    "MinLimit = {'val_mse':1., 'val_FeatRecLoss':1., 'val_kl_Loss_Z':0.01, 'val_kl_Loss_FC':0.01}\n",
    "MaxLimit = {'val_mse':200., 'val_FeatRecLoss':200., 'val_kl_Loss_Z':0.1, 'val_kl_Loss_FC':0.1}\n",
    "RelLoss = RelLossWeight(BetaList=RelLossDic, BetaWeight= WeightDic, MinLimit= MinLimit, MaxLimit = MaxLimit )\n",
    "\n",
    "\n",
    "class RelLossWeight(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, BetaList, LossScaling, MinLimit , MaxLimit , verbose=1):\n",
    "                \n",
    "        self.BetaList = BetaList\n",
    "        self.LossScaling = LossScaling\n",
    "        self.MinLimit = MinLimit\n",
    "        self.MaxLimit = MaxLimit\n",
    "        self.verbose = verbose\n",
    "\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        Losses = np.array([logs[i] for i in self.BetaList.keys()])\n",
    "        Losses = np.maximum(1e-7, Losses)\n",
    "        RelWeights = Losses / np.min(Losses)\n",
    "        RelWeights = {loss:RelWeights[num] * self.LossScaling[loss] for num, loss in enumerate (self.BetaList.keys())}\n",
    "\n",
    "        for loss, beta in self.BetaList.items():\n",
    "            \n",
    "            Value = np.clip(RelWeights[loss] , self.MinLimit[beta], self.MaxLimit[beta])\n",
    "            K.set_value(self.model.get_layer(beta).variables[0], Value)\n",
    "\n",
    "        if self.verbose==1:\n",
    "            print('RelWeights')\n",
    "            print(RelWeights)\n",
    "                       \n",
    "            for key, beta in self.BetaList.items():\n",
    "                print(beta, ': ', self.model.get_layer(beta).variables[0].numpy())\n",
    "\n",
    "'''        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "def ReName (layer, name):\n",
    "    return Lambda(lambda x: x, name=name)(layer)\n",
    "\n",
    "def ParaFilters (layer, name=''):\n",
    "    Fc = Dense(1, activation='sigmoid')(layer)\n",
    "    Fc = tf.clip_by_value(Fc, 1e-7, 1-1e-7)\n",
    "    \n",
    "    # Reparameterization Trick for sampling from Uniformly distribution; ϵ∼U(0,1) \n",
    "    Epsilon = tf.random.uniform(shape=(tf.shape(Fc)[0], Fc.shape[1]))\n",
    "    Epsilon = tf.clip_by_value(Epsilon, 1e-7, 1-1e-7)\n",
    "\n",
    "    LogEps = tf.math.log(Epsilon)\n",
    "    LogNegEps = tf.math.log(1 - Epsilon)\n",
    "    \n",
    "    LogTheta = tf.math.log(Fc)\n",
    "    LogNegTheta = tf.math.log(1-Fc)\n",
    "\n",
    "    Fc = tf.math.sigmoid(LogEps - LogNegEps + LogTheta - LogNegTheta)\n",
    "    Fc = tf.clip_by_value(Fc, 1e-7, 1-1e-7)\n",
    "    Fc = ReName(Fc, name)\n",
    "    \n",
    "    return Fc \n",
    "\n",
    "\n",
    "class Lossweight(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, InitVal = 0., name='Lossweight'):\n",
    "        super(Lossweight, self).__init__(name=name)\n",
    "        self.InitVal = InitVal\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.GenVec = tf.Variable(self.InitVal, trainable=False)\n",
    "    \n",
    "    def call(self, input):\n",
    "\n",
    "        return self.GenVec\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(Lossweight, self).get_config()\n",
    "        config.update({ 'InitVal': self.InitVal })\n",
    "        return config\n",
    "    \n",
    "\n",
    "class RandFCs(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, ):\n",
    "        super(RandFCs, self).__init__(name='FCs')\n",
    "        pass\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.GenVec = tf.Variable(tf.random.uniform(shape=(1,6)), trainable=False)\n",
    "    \n",
    "    def call(self, input):\n",
    "        return tf.tile(self.GenVec , (tf.shape(input)[0],1))\n",
    "    \n",
    "\n",
    "\n",
    "class KLAnneal(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, TargetLossName, Threshold,  BetaName, MaxBeta=0.1, MinBeta=1e-5, AnnealEpoch=100, UnderLimit=0., verbose=1):\n",
    "        \n",
    "        if type(TargetLossName) != list:\n",
    "            TargetLossName = [TargetLossName]\n",
    "        \n",
    "        self.TargetLossName = TargetLossName\n",
    "        self.Threshold = Threshold\n",
    "        self.BetaName = BetaName\n",
    "        self.AnnealIdx = 0\n",
    "        self.verbose = verbose \n",
    "        self.Beta =  np.concatenate([np.array([UnderLimit]), np.linspace(start=MinBeta, stop=MaxBeta, num=AnnealEpoch )])\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        TargetLoss = max([logs[i] for i in self.TargetLossName]) \n",
    "        \n",
    "        if TargetLoss > self.Threshold:\n",
    "            \n",
    "            self.AnnealIdx -= 1\n",
    "            self.AnnealIdx = np.maximum(self.AnnealIdx, 0)\n",
    "            K.set_value(self.model.get_layer(self.BetaName).variables[0], self.Beta[self.AnnealIdx])\n",
    "        else: \n",
    "            self.AnnealIdx += 1\n",
    "            self.AnnealIdx = np.minimum(self.AnnealIdx, len(self.Beta)-1)\n",
    "            K.set_value(self.model.get_layer(self.BetaName).variables[0], self.Beta[self.AnnealIdx])\n",
    "        \n",
    "        if self.verbose==1:\n",
    "            print(self.BetaName+' : ' ,self.model.get_layer(self.BetaName).variables[0].numpy())\n",
    "        elif self.verbose==2:\n",
    "            print('TargetLoss : ', TargetLoss)\n",
    "            print(self.BetaName+' : ' ,self.model.get_layer(self.BetaName).variables[0].numpy())\n",
    "            \n",
    "          \n",
    "\n",
    "class RelLossWeight(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, BetaList, LossScaling, MinLimit , MaxLimit , verbose=1, ToSaveLoss=None, SavePath=None):\n",
    "                \n",
    "        self.BetaList = BetaList\n",
    "        self.LossScaling = LossScaling\n",
    "        self.MinLimit = MinLimit\n",
    "        self.MaxLimit = MaxLimit\n",
    "        self.verbose = verbose\n",
    "        self.ToSaveLoss = ToSaveLoss\n",
    "        self.CheckLoss = np.inf\n",
    "        self.SavePath = SavePath\n",
    "\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        Losses = {key:logs[key]/np.maximum(1e-7,self.model.get_layer(beta).variables[0].numpy()) for key, beta in self.BetaList.items()}\n",
    "\n",
    "        if self.ToSaveLoss is not None:\n",
    "            beta = self.BetaList[self.ToSaveLoss]\n",
    "            CurrentLoss = logs[self.ToSaveLoss]/np.maximum(1e-7,self.model.get_layer(beta).variables[0].numpy())\n",
    "            \n",
    "            if CurrentLoss <= self.CheckLoss:\n",
    "                self.model.save(self.SavePath)\n",
    "                print()\n",
    "                print('the model has been saved since loss has decreased from '+ str(self.CheckLoss)+ ' to ' + str(CurrentLoss))\n",
    "                print()\n",
    "                self.CheckLoss = CurrentLoss\n",
    "                \n",
    "                \n",
    "        WeigLosses = np.maximum(1e-7, np.array(list(Losses.values())))\n",
    "        #print(WeigLosses)\n",
    "        RelWeights = WeigLosses / np.min(WeigLosses)\n",
    "        #print(RelWeights)\n",
    "        RelWeights = {loss:RelWeights[num] * self.LossScaling[loss] for num, loss in enumerate (self.BetaList.keys())}\n",
    "        #print(RelWeights)\n",
    "\n",
    "        for loss, beta in self.BetaList.items():\n",
    "            \n",
    "            Value = np.clip(RelWeights[loss] , self.MinLimit[beta], self.MaxLimit[beta])\n",
    "            K.set_value(self.model.get_layer(beta).variables[0], Value)\n",
    "\n",
    "        if self.verbose==1:\n",
    "\n",
    "            print('------------------------------------')\n",
    "            print('Losses')\n",
    "            for key, value in Losses.items():\n",
    "                print(\"%s: %.7f\" % (key, value))\n",
    "            print()\n",
    "            \n",
    "            print('------------------------------------')\n",
    "            print('RelWeights')\n",
    "            for key, value in RelWeights.items():\n",
    "                print(\"%s: %.7f\" % (key, value))\n",
    "            print('------------------------------------')\n",
    "                       \n",
    "            print('------------------------------------')\n",
    "            print('Beta')\n",
    "            for key, beta in self.BetaList.items():\n",
    "                print(beta, ': ', self.model.get_layer(beta).variables[0].numpy())\n",
    "            print('------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Encoder(SigDim, LatDim= 2, Type = '', MaskingRate = 0.025, NoiseStd = 0.002, MaskStd = 0.1, ReparaStd = 0.1 , Reparam = False):\n",
    "\n",
    "    InpL = Input(shape=(SigDim,))\n",
    "    InpFrame = tf.signal.frame(InpL, 100, 100)\n",
    "\n",
    "    if Reparam:\n",
    "        InpRegul = GaussianNoise(stddev=NoiseStd)(InpFrame, training=Reparam)\n",
    "        MaskVec, NoisVec = MaskingGen(InpRegul, MaskingRate, MaskStd)\n",
    "        EncInp = Masking(mask_value=0.)(InpRegul * MaskVec )\n",
    "        EncOut = InpRegul + NoisVec\n",
    "    else:\n",
    "        EncInp, EncOut = InpFrame, InpFrame\n",
    "\n",
    "    Encoder = Dense(50, activation='relu')(InpFrame)\n",
    "    Encoder = Bidirectional(GRU(30, return_sequences=True))(Encoder)\n",
    "    Encoder = Bidirectional(GRU(30, return_sequences=False))(Encoder)\n",
    "    Encoder = Dense(50, activation='relu')(Encoder)\n",
    "    Encoder = Dense(30, activation='relu')(Encoder)\n",
    "    Encoder = Dense(15, activation='relu')(Encoder)\n",
    "\n",
    "    Z_Mean = Dense(LatDim, activation='linear')(Encoder)\n",
    "    Z_Log_Sigma = Dense(LatDim, activation='relu')(Encoder)\n",
    "    Z_Log_Sigma = ReName(Z_Log_Sigma,'Z_Log_Sigma_'+Type)\n",
    "\n",
    "    \n",
    "    # Reparameterization Trick for sampling from Guassian distribution\n",
    "    Epsilon = tf.random.normal(shape=(tf.shape(Z_Mean)[0], Z_Mean.shape[1]), mean=0., stddev=ReparaStd)\n",
    "\n",
    "    if Reparam==False:\n",
    "        Epsilon = Epsilon * 0\n",
    "\n",
    "    Z_Mean = Z_Mean + tf.exp(0.5 * Z_Log_Sigma) * Epsilon\n",
    "    Z_Mean = ReName(Z_Mean,'Z_Mean_'+Type)\n",
    "    \n",
    "    FCs =   Dense(6, activation='relu')(Encoder)\n",
    "    FCs =   Dense(6, activation='sigmoid')(FCs)\n",
    "    \n",
    "    \n",
    "    # Reparameterization Trick for sampling from Uniformly distribution; ϵ∼U(0,1) \n",
    "    FCs = tf.clip_by_value(FCs, 1e-7, 1-1e-7)\n",
    "    Epsilon = tf.random.uniform(shape=(tf.shape(FCs)[0], FCs.shape[1]))\n",
    "    Epsilon = tf.clip_by_value(Epsilon, 1e-7, 1-1e-7)\n",
    "    \n",
    "    LogEps = tf.math.log(Epsilon)\n",
    "    LogNegEps = tf.math.log(1 - Epsilon)\n",
    "    \n",
    "    LogTheta = tf.math.log(FCs)\n",
    "    LogNegTheta = tf.math.log(1-FCs)\n",
    "    \n",
    "    \n",
    "    FCs = tf.math.sigmoid(LogEps - LogNegEps + LogTheta - LogNegTheta)\n",
    "    FCs = tf.clip_by_value(FCs, 1e-7, 1-1e-7)\n",
    "    FCs = ReName(FCs, 'FCs')\n",
    "    \n",
    "    return [InpL], [Flatten()(EncOut), Z_Mean, FCs]\n",
    "\n",
    "\n",
    "\n",
    "def FeatExtractor(Inps, LatDim= 2, FiltLenList = [301, 301, 301, 301, 301, 301] ):\n",
    "    \n",
    "    EncReInp, InpZ, FCs = Inps\n",
    "    \n",
    "    H_F, L_F, HH_F, HL_F, LH_F, LL_F = tf.split(FCs, 6, axis=1)\n",
    "    \n",
    "\n",
    "    ### Filtering level 1 -------------------------------------------------------------------\n",
    "    ## Filter generation\n",
    "    To_H = GenHighFilter(H_F,  N=FiltLenList[0])\n",
    "    To_L = GenLowFilter(L_F, N=FiltLenList[1])\n",
    "\n",
    "    ## Perform signal filtering level 1\n",
    "    InpFrame =  tf.signal.frame(EncReInp, To_H.shape[-1], 1)\n",
    "    Sig_H = tf.reduce_sum(InpFrame*To_H[:,:,::-1], axis=-1, keepdims=True)\n",
    "    Sig_H = ReName(Sig_H, 'Sig_H_Ext')\n",
    "\n",
    "    InpFrame =  tf.signal.frame(EncReInp, To_L.shape[-1], 1)\n",
    "    Sig_L = tf.reduce_sum(InpFrame*To_L[:,:,::-1], axis=-1, keepdims=True)\n",
    "    Sig_L = ReName(Sig_L, 'Sig_L_Ext')\n",
    "\n",
    "\n",
    "\n",
    "    ### Filtering level HH and HL (from Sig_H) -------------------------------------------------------------------\n",
    "    ## Filter generation\n",
    "    To_HH = GenHighFilter(HH_F, N=FiltLenList[2])\n",
    "    To_HL = GenLowFilter(HL_F, N=FiltLenList[3])\n",
    "\n",
    "    ## Perform signal filtering level 2\n",
    "    Frame_H =  tf.signal.frame(Sig_H[:,:,0], To_HH.shape[-1], 1)\n",
    "    Sig_HH = tf.reduce_sum(Frame_H*To_HH[:,:,::-1], axis=-1, keepdims=True)\n",
    "    Sig_HH = ReName(Sig_HH, 'Sig_HH_Ext')\n",
    "\n",
    "    Frame_H =  tf.signal.frame(Sig_H[:,:,0], To_HL.shape[-1], 1)\n",
    "    Sig_HL = tf.reduce_sum(Frame_H*To_HL[:,:,::-1], axis=-1, keepdims=True)\n",
    "    Sig_HL = ReName(Sig_HL, 'Sig_HL_Ext')\n",
    "\n",
    "\n",
    "    ### Filtering level LH and LL (from Sig_L) -------------------------------------------------------------------\n",
    "    ## Filter generation\n",
    "    To_LH = GenHighFilter(LH_F,  N=FiltLenList[4])\n",
    "    To_LL = GenLowFilter(LL_F,  N=FiltLenList[5])\n",
    "\n",
    "    ## Perform signal filtering level 2\n",
    "    Frame_L =  tf.signal.frame(Sig_L[:,:,0], To_LH.shape[-1], 1)\n",
    "    Sig_LH = tf.reduce_sum(Frame_L*To_LH[:,:,::-1], axis=-1, keepdims=True)\n",
    "    Sig_LH = ReName(Sig_LH, 'Sig_LH_Ext')\n",
    "\n",
    "    Frame_L =  tf.signal.frame(Sig_L[:,:,0], To_LL.shape[-1], 1)\n",
    "    Sig_LL = tf.reduce_sum(Frame_L*To_LL[:,:,::-1], axis=-1, keepdims=True)\n",
    "    Sig_LL = ReName(Sig_LL, 'Sig_LL_Ext')\n",
    "\n",
    "    \n",
    "    return [Flatten()(Sig_HH), Flatten()(Sig_HL), Flatten()(Sig_LH), Flatten()(Sig_LL)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def FeatGenerator (Inp_lat):\n",
    "    \n",
    "    #Inp_lat = tf.concat(Inp_lat, axis=-1)\n",
    "    InpZ, FCCommon, FCEach = Inp_lat\n",
    "    HH_F, HL_F, LH_F, LL_F = tf.split(FCEach, 4, axis=1)\n",
    "    \n",
    "   \n",
    "    Dec_Sig_HH = Dense(10, activation='relu')(tf.concat([InpZ, FCCommon, HH_F], axis=-1))\n",
    "    Dec_Sig_HH = Dense(20, activation='relu')(Dec_Sig_HH)\n",
    "    Dec_Sig_HH = Dense(30, activation='relu')(Dec_Sig_HH)\n",
    "    Dec_Sig_HH = Dense(50, activation='relu')(Dec_Sig_HH)\n",
    "\n",
    "    Dec_Sig_HH = RepeatVector(10 )(Dec_Sig_HH)\n",
    "    Dec_Sig_HH = Bidirectional(GRU(10, return_sequences=True))(Dec_Sig_HH)\n",
    "    Dec_Sig_HH = Bidirectional(GRU(20, return_sequences=True))(Dec_Sig_HH)\n",
    "    Dec_Sig_HH = Dense(40,'tanh')(Dec_Sig_HH)\n",
    "    Sig_HH= Flatten(name='Sig_HH_Gen')(Dec_Sig_HH)\n",
    "    \n",
    "    # ---------------------------------------------------------------------- #\n",
    "    \n",
    "    Dec_Sig_HL = Dense(10, activation='relu')(tf.concat([InpZ, FCCommon, HL_F], axis=-1))\n",
    "    Dec_Sig_HL = Dense(20, activation='relu')(Dec_Sig_HL)\n",
    "    Dec_Sig_HL = Dense(30, activation='relu')(Dec_Sig_HL)\n",
    "    Dec_Sig_HL = Dense(50, activation='relu')(Dec_Sig_HL)\n",
    "\n",
    "    Dec_Sig_HL = RepeatVector(10 )(Dec_Sig_HL)\n",
    "    Dec_Sig_HL = Bidirectional(GRU(10, return_sequences=True))(Dec_Sig_HL)\n",
    "    Dec_Sig_HL = Bidirectional(GRU(20, return_sequences=True))(Dec_Sig_HL)\n",
    "    Dec_Sig_HL = Dense(40,'tanh')(Dec_Sig_HL)\n",
    "    Sig_HL= Flatten(name='Sig_HL_Gen')(Dec_Sig_HL)\n",
    "    \n",
    "    # ---------------------------------------------------------------------- #\n",
    "    \n",
    "    Dec_Sig_LH = Dense(10, activation='relu')(tf.concat([InpZ, FCCommon, LH_F], axis=-1))\n",
    "    Dec_Sig_LH = Dense(20, activation='relu')(Dec_Sig_LH)\n",
    "    Dec_Sig_LH = Dense(30, activation='relu')(Dec_Sig_LH)\n",
    "    Dec_Sig_LH = Dense(50, activation='relu')(Dec_Sig_LH)\n",
    "\n",
    "    Dec_Sig_LH = RepeatVector(10 )(Dec_Sig_LH)\n",
    "    Dec_Sig_LH = Bidirectional(GRU(10, return_sequences=True))(Dec_Sig_LH)\n",
    "    Dec_Sig_LH = Bidirectional(GRU(20, return_sequences=True))(Dec_Sig_LH)\n",
    "    Dec_Sig_LH = Dense(40,'tanh')(Dec_Sig_LH)\n",
    "    Sig_LH= Flatten(name='Sig_LH_Gen')(Dec_Sig_LH)\n",
    "    \n",
    "    # ---------------------------------------------------------------------- #\n",
    "    \n",
    "    Dec_Sig_LL = Dense(10, activation='relu')(tf.concat([InpZ, FCCommon, LL_F], axis=-1))\n",
    "    Dec_Sig_LL = Dense(20, activation='relu')(Dec_Sig_LL)\n",
    "    Dec_Sig_LL = Dense(30, activation='relu')(Dec_Sig_LL)\n",
    "    Dec_Sig_LL = Dense(50, activation='relu')(Dec_Sig_LL)\n",
    "\n",
    "    Dec_Sig_LL = RepeatVector(10 )(Dec_Sig_LL)\n",
    "    Dec_Sig_LL = Bidirectional(GRU(10, return_sequences=True))(Dec_Sig_LL)\n",
    "    Dec_Sig_LL = Bidirectional(GRU(20, return_sequences=True))(Dec_Sig_LL)\n",
    "    Dec_Sig_LL = Dense(40,'tanh')(Dec_Sig_LL)\n",
    "    Sig_LL= Flatten(name='Sig_LL_Gen')(Dec_Sig_LL)\n",
    "    \n",
    "    return  Sig_HH, Sig_HL, Sig_LH, Sig_LL\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def Reconstructor(Inps ):\n",
    "    Sig_HH, Sig_HL, Sig_LH, Sig_LL = Inps\n",
    "\n",
    "    ## GRU NET -------------------------------------------------------------------\n",
    "    Dec_Sig_HH = Reshape((-1, 100))(Sig_HH)\n",
    "    Dec_Sig_HL = Reshape((-1, 100))(Sig_HL)\n",
    "    Dec_Sig_LH = Reshape((-1, 100))(Sig_LH)\n",
    "    Dec_Sig_LL = Reshape((-1, 100))(Sig_LL)\n",
    "\n",
    "    Dec_Sig_HH = Bidirectional(GRU(5), name='Dec_Sig_HH')(Dec_Sig_HH)\n",
    "    Dec_Sig_HL = Bidirectional(GRU(5), name='Dec_Sig_HL')(Dec_Sig_HL)\n",
    "    Dec_Sig_LH = Bidirectional(GRU(5), name='Dec_Sig_LH')(Dec_Sig_LH)\n",
    "    Dec_Sig_LL = Bidirectional(GRU(5), name='Dec_Sig_LL')(Dec_Sig_LL)\n",
    "\n",
    "    Decoder = tf.concat([ Dec_Sig_HH, Dec_Sig_HL, Dec_Sig_LH, Dec_Sig_LL], axis=1)\n",
    "    Decoder = RepeatVector((SigDim//100) )(Decoder)\n",
    "    Decoder = Bidirectional(GRU(50, return_sequences=True))(Decoder)\n",
    "    Decoder = Dense(100, activation='relu')(Decoder)\n",
    "    DecOut = Dense(100, activation='sigmoid')(Decoder)\n",
    "    DecOut = Reshape((SigDim,),name='Out')(DecOut)\n",
    "\n",
    "    \n",
    "    return DecOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Encoder - FeatExtractor\n",
    "EncInp, EncOut = Encoder(SigDim=SigDim, LatDim= LatDim, Type = 'Tr', MaskingRate = MaskingRate, NoiseStd = NoiseStd, MaskStd = MaskStd, ReparaStd = ReparaStd, Reparam=True)\n",
    "FeatExtOut = FeatExtractor(EncOut)\n",
    "\n",
    "### Encoder - FeatGenerator - Reconstruction\n",
    "FeatGenOut = FeatGenerator([EncOut[1],EncOut[2][:, :2], EncOut[2][:, 2:]])\n",
    "FeatGenOut = ReName(FeatGenOut, 'FeatGenOut')\n",
    "\n",
    "ReconOut = Reconstructor(FeatExtOut)\n",
    "ReconOut = ReName(ReconOut, 'ReconOut')\n",
    "\n",
    "### Define the total model\n",
    "SigBandRepModel = Model(EncInp, ReconOut)\n",
    "\n",
    "### Weight controller; Apply beta and capacity \n",
    "Capacity_Z = 0.1 # 0.1 0.05\n",
    "Capacity_Fc = 0.6\n",
    "Beta_Z = Lossweight(name='Beta_Z')(FeatGenOut)\n",
    "Beta_Fc = Lossweight(name='Beta_Fc')(FeatGenOut)\n",
    "Beta_Rec = Lossweight(name='Beta_Rec', InitVal=500.)(FeatGenOut)\n",
    "Beta_Feat = Lossweight(name='Beta_Feat', InitVal=500.)(FeatGenOut)\n",
    "\n",
    "\n",
    "### Adding the RecLoss; \n",
    "MSE = tf.keras.losses.MeanSquaredError()\n",
    "RecLoss = Beta_Rec * MSE(ReconOut, EncInp)\n",
    "SigBandRepModel.add_loss(RecLoss)\n",
    "SigBandRepModel.add_metric(RecLoss, 'RecLoss')\n",
    "\n",
    "\n",
    "### Adding the FeatRecLoss; It allows connection between the extractor and generator\n",
    "FeatRecLoss= Beta_Feat * MSE(tf.concat(FeatGenOut, axis=-1), tf.concat(FeatExtOut, axis=-1))\n",
    "SigBandRepModel.add_loss(FeatRecLoss)\n",
    "SigBandRepModel.add_metric(FeatRecLoss, 'FeatRecLoss')\n",
    "\n",
    "### KL Divergence for p(Z) vs q(Z)\n",
    "Z_Sampled, Z_Log_Sigma = SigBandRepModel.get_layer('Z_Mean_Tr').output, SigBandRepModel.get_layer('Z_Log_Sigma_Tr').output\n",
    "kl_Loss_Z = 0.5 * tf.reduce_sum( Z_Sampled**2  +  tf.exp(Z_Log_Sigma)- Z_Log_Sigma-1, axis=1)    \n",
    "kl_Loss_Z = tf.reduce_mean(kl_Loss_Z )\n",
    "kl_Loss_Z = Beta_Z * tf.abs(kl_Loss_Z - Capacity_Z)\n",
    "\n",
    "### KL Divergence for p(FCs) vs q(FCs)\n",
    "BernP = 0.5 # hyperparameter\n",
    "FCs = SigBandRepModel.get_layer('FCs').output\n",
    "kl_Loss_FC = tf.math.log(FCs) - tf.math.log(BernP) + tf.math.log(1-FCs) - tf.math.log(1-BernP) \n",
    "kl_Loss_FC = tf.reduce_mean(-kl_Loss_FC )\n",
    "kl_Loss_FC = Beta_Fc * tf.abs(kl_Loss_FC - Capacity_Fc)\n",
    "\n",
    "SigBandRepModel.add_loss(kl_Loss_Z )\n",
    "SigBandRepModel.add_metric(kl_Loss_Z , 'kl_Loss_Z')\n",
    "\n",
    "SigBandRepModel.add_loss(kl_Loss_FC )\n",
    "SigBandRepModel.add_metric(kl_Loss_FC , 'kl_Loss_FC')\n",
    "\n",
    "## Model Compile\n",
    "SigBandRepModel.compile(optimizer='adam') \n",
    "\n",
    "### Loss and KLD_Beta controller\n",
    "KLD_Beta_Z = KLAnneal(TargetLossName=['val_FeatRecLoss', 'val_RecLoss'], Threshold=0.001, BetaName='Beta_Z',  MaxBeta=0.1 , MinBeta=0.1, AnnealEpoch=1, UnderLimit=1e-7, verbose=2)\n",
    "KLD_Beta_Fc = KLAnneal(TargetLossName=['val_FeatRecLoss', 'val_RecLoss'], Threshold=0.001, BetaName='Beta_Fc',  MaxBeta=0.005 , MinBeta=0.005, AnnealEpoch=1, UnderLimit=1e-7, verbose=1)\n",
    "\n",
    "RelLossDic = {'val_RecLoss':'Beta_Rec', 'val_FeatRecLoss':'Beta_Feat', 'val_kl_Loss_Z':'Beta_Z', 'val_kl_Loss_FC':'Beta_Fc'}\n",
    "ScalingDic = {'val_RecLoss':100., 'val_FeatRecLoss':100., 'val_kl_Loss_Z':0.1, 'val_kl_Loss_FC':0.1}\n",
    "MinLimit = {'Beta_Rec':1., 'Beta_Feat':1., 'Beta_Z':0.01, 'Beta_Fc':0.01}\n",
    "MaxLimit = {'Beta_Rec':500., 'Beta_Feat':500., 'Beta_Z':0.1, 'Beta_Fc':0.1}\n",
    "RelLoss = RelLossWeight(BetaList=RelLossDic, LossScaling= ScalingDic, MinLimit= MinLimit, MaxLimit = MaxLimit, ToSaveLoss='val_FeatRecLoss' ,  SavePath = ModelSaveSameName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      " 6/92 [>.............................] - ETA: 47s - loss: 0.3588 - RecLoss: 0.2306 - FeatRecLoss: 0.1141 - kl_Loss_Z: 0.0291 - kl_Loss_FC: 0.0017WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2258s vs `on_train_batch_end` time: 0.2759s). Check your callbacks.\n",
      "92/92 [==============================] - 113s 700ms/step - loss: 0.2777 - RecLoss: 0.1069 - FeatRecLoss: 0.1024 - kl_Loss_Z: 0.0327 - kl_Loss_FC: 0.0018 - val_loss: 0.2254 - val_RecLoss: 0.0890 - val_FeatRecLoss: 0.1019 - val_kl_Loss_Z: 0.0328 - val_kl_Loss_FC: 0.0017\n",
      "\n",
      "the model has been saved since loss has decreased from inf to 0.0009535414563917343\n",
      "\n",
      "------------------------------------\n",
      "Losses\n",
      "val_RecLoss: 0.0008899\n",
      "val_FeatRecLoss: 0.0009535\n",
      "val_kl_Loss_Z: 0.3281737\n",
      "val_kl_Loss_FC: 0.0172866\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "RelWeights\n",
      "val_RecLoss: 100.0000000\n",
      "val_FeatRecLoss: 107.1517857\n",
      "val_kl_Loss_Z: 36.8776779\n",
      "val_kl_Loss_FC: 1.9425399\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "Beta\n",
      "Beta_Rec :  100.0\n",
      "Beta_Feat :  107.15179\n",
      "Beta_Z :  0.1\n",
      "Beta_Fc :  0.1\n",
      "------------------------------------\n",
      "Epoch 2/700\n",
      "92/92 [==============================] - 54s 585ms/step - loss: 0.2259 - RecLoss: 0.0885 - FeatRecLoss: 0.1005 - kl_Loss_Z: 0.0340 - kl_Loss_FC: 0.0019 - val_loss: 0.2253 - val_RecLoss: 0.0888 - val_FeatRecLoss: 0.1021 - val_kl_Loss_Z: 0.0326 - val_kl_Loss_FC: 0.0018\n",
      "\n",
      "the model has been saved since loss has decreased from 0.0009535414563917343 to 0.0009531538127886386\n",
      "\n",
      "------------------------------------\n",
      "Losses\n",
      "val_RecLoss: 0.0008879\n",
      "val_FeatRecLoss: 0.0009532\n",
      "val_kl_Loss_Z: 0.3255866\n",
      "val_kl_Loss_FC: 0.0183911\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "RelWeights\n",
      "val_RecLoss: 100.0000000\n",
      "val_FeatRecLoss: 107.3494558\n",
      "val_kl_Loss_Z: 36.6693689\n",
      "val_kl_Loss_FC: 2.0713097\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "Beta\n",
      "Beta_Rec :  100.0\n",
      "Beta_Feat :  107.34946\n",
      "Beta_Z :  0.1\n",
      "Beta_Fc :  0.1\n",
      "------------------------------------\n",
      "Epoch 3/700\n",
      "92/92 [==============================] - 54s 586ms/step - loss: 0.2265 - RecLoss: 0.0884 - FeatRecLoss: 0.1026 - kl_Loss_Z: 0.0338 - kl_Loss_FC: 0.0018 - val_loss: 0.2297 - val_RecLoss: 0.0890 - val_FeatRecLoss: 0.0955 - val_kl_Loss_Z: 0.0432 - val_kl_Loss_FC: 0.0021\n",
      "\n",
      "the model has been saved since loss has decreased from 0.0009531538127886386 to 0.0008893085763143733\n",
      "\n",
      "------------------------------------\n",
      "Losses\n",
      "val_RecLoss: 0.0008895\n",
      "val_FeatRecLoss: 0.0008893\n",
      "val_kl_Loss_Z: 0.4318490\n",
      "val_kl_Loss_FC: 0.0205241\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "RelWeights\n",
      "val_RecLoss: 100.0216431\n",
      "val_FeatRecLoss: 100.0000000\n",
      "val_kl_Loss_Z: 48.5600829\n",
      "val_kl_Loss_FC: 2.3078666\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "Beta\n",
      "Beta_Rec :  100.021645\n",
      "Beta_Feat :  100.0\n",
      "Beta_Z :  0.1\n",
      "Beta_Fc :  0.1\n",
      "------------------------------------\n",
      "Epoch 4/700\n",
      "92/92 [==============================] - 54s 586ms/step - loss: 0.2214 - RecLoss: 0.0886 - FeatRecLoss: 0.0980 - kl_Loss_Z: 0.0326 - kl_Loss_FC: 0.0018 - val_loss: 0.2220 - val_RecLoss: 0.0891 - val_FeatRecLoss: 0.1002 - val_kl_Loss_Z: 0.0309 - val_kl_Loss_FC: 0.0018\n",
      "------------------------------------\n",
      "Losses\n",
      "val_RecLoss: 0.0008909\n",
      "val_FeatRecLoss: 0.0010022\n",
      "val_kl_Loss_Z: 0.3090043\n",
      "val_kl_Loss_FC: 0.0178965\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "RelWeights\n",
      "val_RecLoss: 100.0000000\n",
      "val_FeatRecLoss: 112.4962505\n",
      "val_kl_Loss_Z: 34.6858086\n",
      "val_kl_Loss_FC: 2.0088856\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "Beta\n",
      "Beta_Rec :  100.0\n",
      "Beta_Feat :  112.496254\n",
      "Beta_Z :  0.1\n",
      "Beta_Fc :  0.1\n",
      "------------------------------------\n",
      "Epoch 5/700\n",
      "92/92 [==============================] - 53s 581ms/step - loss: 0.2326 - RecLoss: 0.0887 - FeatRecLoss: 0.1079 - kl_Loss_Z: 0.0345 - kl_Loss_FC: 0.0019 - val_loss: 0.2329 - val_RecLoss: 0.0890 - val_FeatRecLoss: 0.1060 - val_kl_Loss_Z: 0.0362 - val_kl_Loss_FC: 0.0018\n",
      "------------------------------------\n",
      "Losses\n",
      "val_RecLoss: 0.0008898\n",
      "val_FeatRecLoss: 0.0009420\n",
      "val_kl_Loss_Z: 0.3621624\n",
      "val_kl_Loss_FC: 0.0177215\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "RelWeights\n",
      "val_RecLoss: 100.0000000\n",
      "val_FeatRecLoss: 105.8638772\n",
      "val_kl_Loss_Z: 40.7002845\n",
      "val_kl_Loss_FC: 1.9915599\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "Beta\n",
      "Beta_Rec :  100.0\n",
      "Beta_Feat :  105.86388\n",
      "Beta_Z :  0.1\n",
      "Beta_Fc :  0.1\n",
      "------------------------------------\n",
      "Epoch 6/700\n",
      "92/92 [==============================] - 54s 586ms/step - loss: 0.2280 - RecLoss: 0.0889 - FeatRecLoss: 0.1031 - kl_Loss_Z: 0.0329 - kl_Loss_FC: 0.0019 - val_loss: 0.2249 - val_RecLoss: 0.0895 - val_FeatRecLoss: 0.1005 - val_kl_Loss_Z: 0.0332 - val_kl_Loss_FC: 0.0017\n",
      "------------------------------------\n",
      "Losses\n",
      "val_RecLoss: 0.0008949\n",
      "val_FeatRecLoss: 0.0009493\n",
      "val_kl_Loss_Z: 0.3321222\n",
      "val_kl_Loss_FC: 0.0174630\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "RelWeights\n",
      "val_RecLoss: 100.0000000\n",
      "val_FeatRecLoss: 106.0772047\n",
      "val_kl_Loss_Z: 37.1138139\n",
      "val_kl_Loss_FC: 1.9514447\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "Beta\n",
      "Beta_Rec :  100.0\n",
      "Beta_Feat :  106.0772\n",
      "Beta_Z :  0.1\n",
      "Beta_Fc :  0.1\n",
      "------------------------------------\n",
      "Epoch 7/700\n",
      "92/92 [==============================] - 54s 589ms/step - loss: 0.2244 - RecLoss: 0.0888 - FeatRecLoss: 0.1012 - kl_Loss_Z: 0.0338 - kl_Loss_FC: 0.0019 - val_loss: 0.2287 - val_RecLoss: 0.0893 - val_FeatRecLoss: 0.1034 - val_kl_Loss_Z: 0.0342 - val_kl_Loss_FC: 0.0018\n",
      "------------------------------------\n",
      "Losses\n",
      "val_RecLoss: 0.0008929\n",
      "val_FeatRecLoss: 0.0009746\n",
      "val_kl_Loss_Z: 0.3420271\n",
      "val_kl_Loss_FC: 0.0183570\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "RelWeights\n",
      "val_RecLoss: 100.0000000\n",
      "val_FeatRecLoss: 109.1444409\n",
      "val_kl_Loss_Z: 38.3051178\n",
      "val_kl_Loss_FC: 2.0558811\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "Beta\n",
      "Beta_Rec :  100.0\n",
      "Beta_Feat :  109.14444\n",
      "Beta_Z :  0.1\n",
      "Beta_Fc :  0.1\n",
      "------------------------------------\n",
      "Epoch 8/700\n",
      "92/92 [==============================] - 54s 582ms/step - loss: 0.2303 - RecLoss: 0.0887 - FeatRecLoss: 0.1052 - kl_Loss_Z: 0.0335 - kl_Loss_FC: 0.0020 - val_loss: 0.2284 - val_RecLoss: 0.0889 - val_FeatRecLoss: 0.1010 - val_kl_Loss_Z: 0.0368 - val_kl_Loss_FC: 0.0016\n",
      "------------------------------------\n",
      "Losses\n",
      "val_RecLoss: 0.0008893\n",
      "val_FeatRecLoss: 0.0009255\n",
      "val_kl_Loss_Z: 0.3681560\n",
      "val_kl_Loss_FC: 0.0164756\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "RelWeights\n",
      "val_RecLoss: 100.0000000\n",
      "val_FeatRecLoss: 104.0684820\n",
      "val_kl_Loss_Z: 41.3976261\n",
      "val_kl_Loss_FC: 1.8526182\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "Beta\n",
      "Beta_Rec :  100.0\n",
      "Beta_Feat :  104.06848\n",
      "Beta_Z :  0.1\n",
      "Beta_Fc :  0.1\n",
      "------------------------------------\n",
      "Epoch 9/700\n",
      "92/92 [==============================] - 54s 583ms/step - loss: 0.2248 - RecLoss: 0.0889 - FeatRecLoss: 0.1019 - kl_Loss_Z: 0.0327 - kl_Loss_FC: 0.0020 - val_loss: 0.2237 - val_RecLoss: 0.0889 - val_FeatRecLoss: 0.0982 - val_kl_Loss_Z: 0.0345 - val_kl_Loss_FC: 0.0021\n",
      "------------------------------------\n",
      "Losses\n",
      "val_RecLoss: 0.0008893\n",
      "val_FeatRecLoss: 0.0009433\n",
      "val_kl_Loss_Z: 0.3449317\n",
      "val_kl_Loss_FC: 0.0213404\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "RelWeights\n",
      "val_RecLoss: 100.0000000\n",
      "val_FeatRecLoss: 106.0797485\n",
      "val_kl_Loss_Z: 38.7888119\n",
      "val_kl_Loss_FC: 2.3998092\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "Beta\n",
      "Beta_Rec :  100.0\n",
      "Beta_Feat :  106.07975\n",
      "Beta_Z :  0.1\n",
      "Beta_Fc :  0.1\n",
      "------------------------------------\n",
      "Epoch 10/700\n",
      "92/92 [==============================] - 54s 583ms/step - loss: 0.2251 - RecLoss: 0.0888 - FeatRecLoss: 0.1015 - kl_Loss_Z: 0.0339 - kl_Loss_FC: 0.0018 - val_loss: 0.2274 - val_RecLoss: 0.0894 - val_FeatRecLoss: 0.1034 - val_kl_Loss_Z: 0.0329 - val_kl_Loss_FC: 0.0017\n",
      "------------------------------------\n",
      "Losses\n",
      "val_RecLoss: 0.0008936\n",
      "val_FeatRecLoss: 0.0009745\n",
      "val_kl_Loss_Z: 0.3293500\n",
      "val_kl_Loss_FC: 0.0173366\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "RelWeights\n",
      "val_RecLoss: 100.0000000\n",
      "val_FeatRecLoss: 109.0522240\n",
      "val_kl_Loss_Z: 36.8548433\n",
      "val_kl_Loss_FC: 1.9399927\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "Beta\n",
      "Beta_Rec :  100.0\n",
      "Beta_Feat :  109.05222\n",
      "Beta_Z :  0.1\n",
      "Beta_Fc :  0.1\n",
      "------------------------------------\n",
      "Epoch 11/700\n",
      "92/92 [==============================] - 54s 584ms/step - loss: 0.2289 - RecLoss: 0.0890 - FeatRecLoss: 0.1036 - kl_Loss_Z: 0.0342 - kl_Loss_FC: 0.0018 - val_loss: 0.2276 - val_RecLoss: 0.0889 - val_FeatRecLoss: 0.1016 - val_kl_Loss_Z: 0.0353 - val_kl_Loss_FC: 0.0019\n",
      "------------------------------------\n",
      "Losses\n",
      "val_RecLoss: 0.0008892\n",
      "val_FeatRecLoss: 0.0009314\n",
      "val_kl_Loss_Z: 0.3525593\n",
      "val_kl_Loss_FC: 0.0187365\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "RelWeights\n",
      "val_RecLoss: 100.0000000\n",
      "val_FeatRecLoss: 104.7487027\n",
      "val_kl_Loss_Z: 39.6506443\n",
      "val_kl_Loss_FC: 2.1072039\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "Beta\n",
      "Beta_Rec :  100.0\n",
      "Beta_Feat :  104.7487\n",
      "Beta_Z :  0.1\n",
      "Beta_Fc :  0.1\n",
      "------------------------------------\n",
      "Epoch 12/700\n",
      "92/92 [==============================] - 54s 588ms/step - loss: 0.2239 - RecLoss: 0.0888 - FeatRecLoss: 0.1011 - kl_Loss_Z: 0.0326 - kl_Loss_FC: 0.0019 - val_loss: 0.2294 - val_RecLoss: 0.0895 - val_FeatRecLoss: 0.1029 - val_kl_Loss_Z: 0.0351 - val_kl_Loss_FC: 0.0020\n",
      "------------------------------------\n",
      "Losses\n",
      "val_RecLoss: 0.0008947\n",
      "val_FeatRecLoss: 0.0009819\n",
      "val_kl_Loss_Z: 0.3509033\n",
      "val_kl_Loss_FC: 0.0202498\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "RelWeights\n",
      "val_RecLoss: 100.0000000\n",
      "val_FeatRecLoss: 109.7497392\n",
      "val_kl_Loss_Z: 39.2220131\n",
      "val_kl_Loss_FC: 2.2634104\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "Beta\n",
      "Beta_Rec :  100.0\n",
      "Beta_Feat :  109.74974\n",
      "Beta_Z :  0.1\n",
      "Beta_Fc :  0.1\n",
      "------------------------------------\n",
      "Epoch 13/700\n",
      "92/92 [==============================] - 54s 585ms/step - loss: 0.2380 - RecLoss: 0.0889 - FeatRecLoss: 0.1096 - kl_Loss_Z: 0.0335 - kl_Loss_FC: 0.0019 - val_loss: 0.2297 - val_RecLoss: 0.0893 - val_FeatRecLoss: 0.1064 - val_kl_Loss_Z: 0.0322 - val_kl_Loss_FC: 0.0018\n",
      "------------------------------------\n",
      "Losses\n",
      "val_RecLoss: 0.0008933\n",
      "val_FeatRecLoss: 0.0009696\n",
      "val_kl_Loss_Z: 0.3218012\n",
      "val_kl_Loss_FC: 0.0182776\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "RelWeights\n",
      "val_RecLoss: 100.0000000\n",
      "val_FeatRecLoss: 108.5481224\n",
      "val_kl_Loss_Z: 36.0254338\n",
      "val_kl_Loss_FC: 2.0461692\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "Beta\n",
      "Beta_Rec :  100.0\n",
      "Beta_Feat :  108.54813\n",
      "Beta_Z :  0.1\n",
      "Beta_Fc :  0.1\n",
      "------------------------------------\n",
      "Epoch 14/700\n",
      "92/92 [==============================] - 54s 586ms/step - loss: 0.2288 - RecLoss: 0.0889 - FeatRecLoss: 0.1037 - kl_Loss_Z: 0.0339 - kl_Loss_FC: 0.0018 - val_loss: 0.2301 - val_RecLoss: 0.0895 - val_FeatRecLoss: 0.1057 - val_kl_Loss_Z: 0.0333 - val_kl_Loss_FC: 0.0017\n",
      "------------------------------------\n",
      "Losses\n",
      "val_RecLoss: 0.0008947\n",
      "val_FeatRecLoss: 0.0009736\n",
      "val_kl_Loss_Z: 0.3331756\n",
      "val_kl_Loss_FC: 0.0165898\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "RelWeights\n",
      "val_RecLoss: 100.0000000\n",
      "val_FeatRecLoss: 108.8156875\n",
      "val_kl_Loss_Z: 37.2389884\n",
      "val_kl_Loss_FC: 1.8542405\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "Beta\n",
      "Beta_Rec :  100.0\n",
      "Beta_Feat :  108.81569\n",
      "Beta_Z :  0.1\n",
      "Beta_Fc :  0.1\n",
      "------------------------------------\n",
      "Epoch 15/700\n",
      "92/92 [==============================] - 54s 582ms/step - loss: 0.2303 - RecLoss: 0.0891 - FeatRecLoss: 0.1062 - kl_Loss_Z: 0.0336 - kl_Loss_FC: 0.0019 - val_loss: 0.2300 - val_RecLoss: 0.0891 - val_FeatRecLoss: 0.1032 - val_kl_Loss_Z: 0.0360 - val_kl_Loss_FC: 0.0017\n",
      "------------------------------------\n",
      "Losses\n",
      "val_RecLoss: 0.0008908\n",
      "val_FeatRecLoss: 0.0009484\n",
      "val_kl_Loss_Z: 0.3595288\n",
      "val_kl_Loss_FC: 0.0171478\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "RelWeights\n",
      "val_RecLoss: 100.0000000\n",
      "val_FeatRecLoss: 106.4739547\n",
      "val_kl_Loss_Z: 40.3611443\n",
      "val_kl_Loss_FC: 1.9250366\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "Beta\n",
      "Beta_Rec :  100.0\n",
      "Beta_Feat :  106.47395\n",
      "Beta_Z :  0.1\n",
      "Beta_Fc :  0.1\n",
      "------------------------------------\n",
      "Epoch 16/700\n",
      "92/92 [==============================] - 54s 584ms/step - loss: 0.2275 - RecLoss: 0.0889 - FeatRecLoss: 0.1051 - kl_Loss_Z: 0.0329 - kl_Loss_FC: 0.0019 - val_loss: 0.2293 - val_RecLoss: 0.0895 - val_FeatRecLoss: 0.1054 - val_kl_Loss_Z: 0.0325 - val_kl_Loss_FC: 0.0019\n",
      "------------------------------------\n",
      "Losses\n",
      "val_RecLoss: 0.0008946\n",
      "val_FeatRecLoss: 0.0009902\n",
      "val_kl_Loss_Z: 0.3252502\n",
      "val_kl_Loss_FC: 0.0186786\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "RelWeights\n",
      "val_RecLoss: 100.0000000\n",
      "val_FeatRecLoss: 110.6890625\n",
      "val_kl_Loss_Z: 36.3562642\n",
      "val_kl_Loss_FC: 2.0878804\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "Beta\n",
      "Beta_Rec :  100.0\n",
      "Beta_Feat :  110.689064\n",
      "Beta_Z :  0.1\n",
      "Beta_Fc :  0.1\n",
      "------------------------------------\n",
      "Epoch 17/700\n",
      "92/92 [==============================] - 54s 587ms/step - loss: 0.2329 - RecLoss: 0.0891 - FeatRecLoss: 0.1080 - kl_Loss_Z: 0.0345 - kl_Loss_FC: 0.0019 - val_loss: 0.2380 - val_RecLoss: 0.0894 - val_FeatRecLoss: 0.1120 - val_kl_Loss_Z: 0.0346 - val_kl_Loss_FC: 0.0020\n",
      "------------------------------------\n",
      "Losses\n",
      "val_RecLoss: 0.0008936\n",
      "val_FeatRecLoss: 0.0010119\n",
      "val_kl_Loss_Z: 0.3459249\n",
      "val_kl_Loss_FC: 0.0199559\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "RelWeights\n",
      "val_RecLoss: 100.0000000\n",
      "val_FeatRecLoss: 113.2452367\n",
      "val_kl_Loss_Z: 38.7125620\n",
      "val_kl_Loss_FC: 2.2332662\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "Beta\n",
      "Beta_Rec :  100.0\n",
      "Beta_Feat :  113.24524\n",
      "Beta_Z :  0.1\n",
      "Beta_Fc :  0.1\n",
      "------------------------------------\n",
      "Epoch 18/700\n",
      "92/92 [==============================] - 54s 587ms/step - loss: 0.2371 - RecLoss: 0.0891 - FeatRecLoss: 0.1101 - kl_Loss_Z: 0.0350 - kl_Loss_FC: 0.0019 - val_loss: 0.2351 - val_RecLoss: 0.0895 - val_FeatRecLoss: 0.1105 - val_kl_Loss_Z: 0.0331 - val_kl_Loss_FC: 0.0019\n",
      "------------------------------------\n",
      "Losses\n",
      "val_RecLoss: 0.0008947\n",
      "val_FeatRecLoss: 0.0009758\n",
      "val_kl_Loss_Z: 0.3314970\n",
      "val_kl_Loss_FC: 0.0193764\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "RelWeights\n",
      "val_RecLoss: 100.0000000\n",
      "val_FeatRecLoss: 109.0568337\n",
      "val_kl_Loss_Z: 37.0495052\n",
      "val_kl_Loss_FC: 2.1655861\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "Beta\n",
      "Beta_Rec :  100.0\n",
      "Beta_Feat :  109.05683\n",
      "Beta_Z :  0.1\n",
      "Beta_Fc :  0.1\n",
      "------------------------------------\n",
      "Epoch 19/700\n",
      "92/92 [==============================] - 54s 588ms/step - loss: 0.2306 - RecLoss: 0.0890 - FeatRecLoss: 0.1046 - kl_Loss_Z: 0.0343 - kl_Loss_FC: 0.0019 - val_loss: 0.2285 - val_RecLoss: 0.0894 - val_FeatRecLoss: 0.1019 - val_kl_Loss_Z: 0.0353 - val_kl_Loss_FC: 0.0019\n",
      "------------------------------------\n",
      "Losses\n",
      "val_RecLoss: 0.0008939\n",
      "val_FeatRecLoss: 0.0009345\n",
      "val_kl_Loss_Z: 0.3525487\n",
      "val_kl_Loss_FC: 0.0193457\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "RelWeights\n",
      "val_RecLoss: 100.0000000\n",
      "val_FeatRecLoss: 104.5405299\n",
      "val_kl_Loss_Z: 39.4390017\n",
      "val_kl_Loss_FC: 2.1641665\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "Beta\n",
      "Beta_Rec :  100.0\n",
      "Beta_Feat :  104.54053\n",
      "Beta_Z :  0.1\n",
      "Beta_Fc :  0.1\n",
      "------------------------------------\n",
      "Epoch 20/700\n",
      "92/92 [==============================] - 54s 590ms/step - loss: 0.2247 - RecLoss: 0.0887 - FeatRecLoss: 0.1012 - kl_Loss_Z: 0.0335 - kl_Loss_FC: 0.0019 - val_loss: 0.2251 - val_RecLoss: 0.0894 - val_FeatRecLoss: 0.1023 - val_kl_Loss_Z: 0.0318 - val_kl_Loss_FC: 0.0017\n",
      "------------------------------------\n",
      "Losses\n",
      "val_RecLoss: 0.0008941\n",
      "val_FeatRecLoss: 0.0009782\n",
      "val_kl_Loss_Z: 0.3180731\n",
      "val_kl_Loss_FC: 0.0166796\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "RelWeights\n",
      "val_RecLoss: 100.0000000\n",
      "val_FeatRecLoss: 109.3978213\n",
      "val_kl_Loss_Z: 35.5736523\n",
      "val_kl_Loss_FC: 1.8654698\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "Beta\n",
      "Beta_Rec :  100.0\n",
      "Beta_Feat :  109.39782\n",
      "Beta_Z :  0.1\n",
      "Beta_Fc :  0.1\n",
      "------------------------------------\n",
      "Epoch 21/700\n",
      "92/92 [==============================] - 54s 586ms/step - loss: 0.2295 - RecLoss: 0.0889 - FeatRecLoss: 0.1050 - kl_Loss_Z: 0.0348 - kl_Loss_FC: 0.0019 - val_loss: 0.2293 - val_RecLoss: 0.0893 - val_FeatRecLoss: 0.1039 - val_kl_Loss_Z: 0.0341 - val_kl_Loss_FC: 0.0019\n",
      "------------------------------------\n",
      "Losses\n",
      "val_RecLoss: 0.0008934\n",
      "val_FeatRecLoss: 0.0009500\n",
      "val_kl_Loss_Z: 0.3409046\n",
      "val_kl_Loss_FC: 0.0189269\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "RelWeights\n",
      "val_RecLoss: 100.0000000\n",
      "val_FeatRecLoss: 106.3408064\n",
      "val_kl_Loss_Z: 38.1585895\n",
      "val_kl_Loss_FC: 2.1185477\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "Beta\n",
      "Beta_Rec :  100.0\n",
      "Beta_Feat :  106.340805\n",
      "Beta_Z :  0.1\n",
      "Beta_Fc :  0.1\n",
      "------------------------------------\n",
      "Epoch 22/700\n",
      "92/92 [==============================] - 54s 587ms/step - loss: 0.2256 - RecLoss: 0.0890 - FeatRecLoss: 0.1010 - kl_Loss_Z: 0.0332 - kl_Loss_FC: 0.0018 - val_loss: 0.2236 - val_RecLoss: 0.0887 - val_FeatRecLoss: 0.0993 - val_kl_Loss_Z: 0.0339 - val_kl_Loss_FC: 0.0017\n",
      "------------------------------------\n",
      "Losses\n",
      "val_RecLoss: 0.0008874\n",
      "val_FeatRecLoss: 0.0009338\n",
      "val_kl_Loss_Z: 0.3386638\n",
      "val_kl_Loss_FC: 0.0173954\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "RelWeights\n",
      "val_RecLoss: 100.0000000\n",
      "val_FeatRecLoss: 105.2233847\n",
      "val_kl_Loss_Z: 38.1634269\n",
      "val_kl_Loss_FC: 1.9602555\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "Beta\n",
      "Beta_Rec :  100.0\n",
      "Beta_Feat :  105.22338\n",
      "Beta_Z :  0.1\n",
      "Beta_Fc :  0.1\n",
      "------------------------------------\n",
      "Epoch 23/700\n",
      "92/92 [==============================] - 54s 583ms/step - loss: 0.2223 - RecLoss: 0.0888 - FeatRecLoss: 0.0987 - kl_Loss_Z: 0.0334 - kl_Loss_FC: 0.0019 - val_loss: 0.2238 - val_RecLoss: 0.0893 - val_FeatRecLoss: 0.0991 - val_kl_Loss_Z: 0.0336 - val_kl_Loss_FC: 0.0018\n",
      "------------------------------------\n",
      "Losses\n",
      "val_RecLoss: 0.0008925\n",
      "val_FeatRecLoss: 0.0009421\n",
      "val_kl_Loss_Z: 0.3357751\n",
      "val_kl_Loss_FC: 0.0182984\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "RelWeights\n",
      "val_RecLoss: 100.0000000\n",
      "val_FeatRecLoss: 105.5549056\n",
      "val_kl_Loss_Z: 37.6204439\n",
      "val_kl_Loss_FC: 2.0501609\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "Beta\n",
      "Beta_Rec :  100.0\n",
      "Beta_Feat :  105.55491\n",
      "Beta_Z :  0.1\n",
      "Beta_Fc :  0.1\n",
      "------------------------------------\n",
      "Epoch 24/700\n",
      "92/92 [==============================] - 54s 582ms/step - loss: 0.2230 - RecLoss: 0.0889 - FeatRecLoss: 0.0990 - kl_Loss_Z: 0.0335 - kl_Loss_FC: 0.0018 - val_loss: 0.2248 - val_RecLoss: 0.0897 - val_FeatRecLoss: 0.1022 - val_kl_Loss_Z: 0.0312 - val_kl_Loss_FC: 0.0017\n",
      "------------------------------------\n",
      "Losses\n",
      "val_RecLoss: 0.0008971\n",
      "val_FeatRecLoss: 0.0009686\n",
      "val_kl_Loss_Z: 0.3115208\n",
      "val_kl_Loss_FC: 0.0168740\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "RelWeights\n",
      "val_RecLoss: 100.0000000\n",
      "val_FeatRecLoss: 107.9748581\n",
      "val_kl_Loss_Z: 34.7266446\n",
      "val_kl_Loss_FC: 1.8810237\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "Beta\n",
      "Beta_Rec :  100.0\n",
      "Beta_Feat :  107.97486\n",
      "Beta_Z :  0.1\n",
      "Beta_Fc :  0.1\n",
      "------------------------------------\n",
      "Epoch 25/700\n",
      "92/92 [==============================] - 54s 582ms/step - loss: 0.2254 - RecLoss: 0.0889 - FeatRecLoss: 0.1009 - kl_Loss_Z: 0.0342 - kl_Loss_FC: 0.0019 - val_loss: 0.2264 - val_RecLoss: 0.0890 - val_FeatRecLoss: 0.1027 - val_kl_Loss_Z: 0.0329 - val_kl_Loss_FC: 0.0018\n",
      "------------------------------------\n",
      "Losses\n",
      "val_RecLoss: 0.0008902\n",
      "val_FeatRecLoss: 0.0009510\n",
      "val_kl_Loss_Z: 0.3288943\n",
      "val_kl_Loss_FC: 0.0175625\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "RelWeights\n",
      "val_RecLoss: 100.0000000\n",
      "val_FeatRecLoss: 106.8280270\n",
      "val_kl_Loss_Z: 36.9450107\n",
      "val_kl_Loss_FC: 1.9728161\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "Beta\n",
      "Beta_Rec :  100.0\n",
      "Beta_Feat :  106.828026\n",
      "Beta_Z :  0.1\n",
      "Beta_Fc :  0.1\n",
      "------------------------------------\n",
      "Epoch 26/700\n",
      "92/92 [==============================] - 54s 585ms/step - loss: 0.2242 - RecLoss: 0.0888 - FeatRecLoss: 0.0998 - kl_Loss_Z: 0.0338 - kl_Loss_FC: 0.0019 - val_loss: 0.2255 - val_RecLoss: 0.0896 - val_FeatRecLoss: 0.1001 - val_kl_Loss_Z: 0.0338 - val_kl_Loss_FC: 0.0019\n",
      "------------------------------------\n",
      "Losses\n",
      "val_RecLoss: 0.0008963\n",
      "val_FeatRecLoss: 0.0009375\n",
      "val_kl_Loss_Z: 0.3376761\n",
      "val_kl_Loss_FC: 0.0193138\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "RelWeights\n",
      "val_RecLoss: 100.0000000\n",
      "val_FeatRecLoss: 104.5986833\n",
      "val_kl_Loss_Z: 37.6759603\n",
      "val_kl_Loss_FC: 2.1549191\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "Beta\n",
      "Beta_Rec :  100.0\n",
      "Beta_Feat :  104.59869\n",
      "Beta_Z :  0.1\n",
      "Beta_Fc :  0.1\n",
      "------------------------------------\n",
      "Epoch 27/700\n",
      "92/92 [==============================] - 54s 584ms/step - loss: 0.2221 - RecLoss: 0.0889 - FeatRecLoss: 0.0975 - kl_Loss_Z: 0.0337 - kl_Loss_FC: 0.0019 - val_loss: 0.2221 - val_RecLoss: 0.0898 - val_FeatRecLoss: 0.0976 - val_kl_Loss_Z: 0.0328 - val_kl_Loss_FC: 0.0018\n",
      "------------------------------------\n",
      "Losses\n",
      "val_RecLoss: 0.0008980\n",
      "val_FeatRecLoss: 0.0009335\n",
      "val_kl_Loss_Z: 0.3284486\n",
      "val_kl_Loss_FC: 0.0184538\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "RelWeights\n",
      "val_RecLoss: 100.0000000\n",
      "val_FeatRecLoss: 103.9490119\n",
      "val_kl_Loss_Z: 36.5745933\n",
      "val_kl_Loss_FC: 2.0549338\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "Beta\n",
      "Beta_Rec :  100.0\n",
      "Beta_Feat :  103.94901\n",
      "Beta_Z :  0.1\n",
      "Beta_Fc :  0.1\n",
      "------------------------------------\n",
      "Epoch 28/700\n",
      "92/92 [==============================] - 54s 587ms/step - loss: 0.2219 - RecLoss: 0.0889 - FeatRecLoss: 0.0994 - kl_Loss_Z: 0.0329 - kl_Loss_FC: 0.0020 - val_loss: 0.2250 - val_RecLoss: 0.0899 - val_FeatRecLoss: 0.0996 - val_kl_Loss_Z: 0.0335 - val_kl_Loss_FC: 0.0020\n",
      "------------------------------------\n",
      "Losses\n",
      "val_RecLoss: 0.0008987\n",
      "val_FeatRecLoss: 0.0009586\n",
      "val_kl_Loss_Z: 0.3350202\n",
      "val_kl_Loss_FC: 0.0197099\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "RelWeights\n",
      "val_RecLoss: 100.0000000\n",
      "val_FeatRecLoss: 106.6648604\n",
      "val_kl_Loss_Z: 37.2784862\n",
      "val_kl_Loss_FC: 2.1931634\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "Beta\n",
      "Beta_Rec :  100.0\n",
      "Beta_Feat :  106.66486\n",
      "Beta_Z :  0.1\n",
      "Beta_Fc :  0.1\n",
      "------------------------------------\n",
      "Epoch 29/700\n",
      "92/92 [==============================] - 54s 589ms/step - loss: 0.2246 - RecLoss: 0.0887 - FeatRecLoss: 0.1005 - kl_Loss_Z: 0.0336 - kl_Loss_FC: 0.0018 - val_loss: 0.2260 - val_RecLoss: 0.0891 - val_FeatRecLoss: 0.1053 - val_kl_Loss_Z: 0.0295 - val_kl_Loss_FC: 0.0021\n",
      "------------------------------------\n",
      "Losses\n",
      "val_RecLoss: 0.0008909\n",
      "val_FeatRecLoss: 0.0009875\n",
      "val_kl_Loss_Z: 0.2951286\n",
      "val_kl_Loss_FC: 0.0210448\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "RelWeights\n",
      "val_RecLoss: 100.0000000\n",
      "val_FeatRecLoss: 110.8455536\n",
      "val_kl_Loss_Z: 33.1277675\n",
      "val_kl_Loss_FC: 2.3622469\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "Beta\n",
      "Beta_Rec :  100.0\n",
      "Beta_Feat :  110.84555\n",
      "Beta_Z :  0.1\n",
      "Beta_Fc :  0.1\n",
      "------------------------------------\n",
      "Epoch 30/700\n",
      "92/92 [==============================] - 54s 586ms/step - loss: 0.2302 - RecLoss: 0.0890 - FeatRecLoss: 0.1036 - kl_Loss_Z: 0.0346 - kl_Loss_FC: 0.0018 - val_loss: 0.2303 - val_RecLoss: 0.0895 - val_FeatRecLoss: 0.1040 - val_kl_Loss_Z: 0.0350 - val_kl_Loss_FC: 0.0019\n",
      "------------------------------------\n",
      "Losses\n",
      "val_RecLoss: 0.0008947\n",
      "val_FeatRecLoss: 0.0009382\n",
      "val_kl_Loss_Z: 0.3503445\n",
      "val_kl_Loss_FC: 0.0185102\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "RelWeights\n",
      "val_RecLoss: 100.0000000\n",
      "val_FeatRecLoss: 104.8578564\n",
      "val_kl_Loss_Z: 39.1575642\n",
      "val_kl_Loss_FC: 2.0688597\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "Beta\n",
      "Beta_Rec :  100.0\n",
      "Beta_Feat :  104.85786\n",
      "Beta_Z :  0.1\n",
      "Beta_Fc :  0.1\n",
      "------------------------------------\n",
      "Epoch 31/700\n",
      "92/92 [==============================] - 55s 595ms/step - loss: 0.2251 - RecLoss: 0.0887 - FeatRecLoss: 0.1026 - kl_Loss_Z: 0.0326 - kl_Loss_FC: 0.0019 - val_loss: 0.2271 - val_RecLoss: 0.0897 - val_FeatRecLoss: 0.1040 - val_kl_Loss_Z: 0.0316 - val_kl_Loss_FC: 0.0018\n",
      "------------------------------------\n",
      "Losses\n",
      "val_RecLoss: 0.0008970\n",
      "val_FeatRecLoss: 0.0009915\n",
      "val_kl_Loss_Z: 0.3164294\n",
      "val_kl_Loss_FC: 0.0180661\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "RelWeights\n",
      "val_RecLoss: 100.0000000\n",
      "val_FeatRecLoss: 110.5407693\n",
      "val_kl_Loss_Z: 35.2771327\n",
      "val_kl_Loss_FC: 2.0140998\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "Beta\n",
      "Beta_Rec :  100.0\n",
      "Beta_Feat :  110.54077\n",
      "Beta_Z :  0.1\n",
      "Beta_Fc :  0.1\n",
      "------------------------------------\n",
      "Epoch 32/700\n",
      "92/92 [==============================] - 55s 593ms/step - loss: 0.2305 - RecLoss: 0.0888 - FeatRecLoss: 0.1063 - kl_Loss_Z: 0.0339 - kl_Loss_FC: 0.0017 - val_loss: 0.2321 - val_RecLoss: 0.0895 - val_FeatRecLoss: 0.1056 - val_kl_Loss_Z: 0.0353 - val_kl_Loss_FC: 0.0017\n",
      "------------------------------------\n",
      "Losses\n",
      "val_RecLoss: 0.0008947\n",
      "val_FeatRecLoss: 0.0009557\n",
      "val_kl_Loss_Z: 0.3529538\n",
      "val_kl_Loss_FC: 0.0170904\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "RelWeights\n",
      "val_RecLoss: 100.0000000\n",
      "val_FeatRecLoss: 106.8181550\n",
      "val_kl_Loss_Z: 39.4506198\n",
      "val_kl_Loss_FC: 1.9102377\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "Beta\n",
      "Beta_Rec :  100.0\n",
      "Beta_Feat :  106.81815\n",
      "Beta_Z :  0.1\n",
      "Beta_Fc :  0.1\n",
      "------------------------------------\n",
      "Epoch 33/700\n",
      "92/92 [==============================] - 54s 590ms/step - loss: 0.2278 - RecLoss: 0.0885 - FeatRecLoss: 0.1030 - kl_Loss_Z: 0.0339 - kl_Loss_FC: 0.0019 - val_loss: 0.2278 - val_RecLoss: 0.0888 - val_FeatRecLoss: 0.1038 - val_kl_Loss_Z: 0.0335 - val_kl_Loss_FC: 0.0017\n",
      "------------------------------------\n",
      "Losses\n",
      "val_RecLoss: 0.0008875\n",
      "val_FeatRecLoss: 0.0009717\n",
      "val_kl_Loss_Z: 0.3354602\n",
      "val_kl_Loss_FC: 0.0172401\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "RelWeights\n",
      "val_RecLoss: 100.0000000\n",
      "val_FeatRecLoss: 109.4808269\n",
      "val_kl_Loss_Z: 37.7965532\n",
      "val_kl_Loss_FC: 1.9424588\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "Beta\n",
      "Beta_Rec :  100.0\n",
      "Beta_Feat :  109.48083\n",
      "Beta_Z :  0.1\n",
      "Beta_Fc :  0.1\n",
      "------------------------------------\n",
      "Epoch 34/700\n",
      "40/92 [============>.................] - ETA: 29s - loss: 0.2294 - RecLoss: 0.0887 - FeatRecLoss: 0.1043 - kl_Loss_Z: 0.0345 - kl_Loss_FC: 0.0018"
     ]
    }
   ],
   "source": [
    "SigBandRepModel.load_weights(ModelSaveSameName)\n",
    "#ModelSave = ModelCheckpoint(filepath=ModelSaveSameName, monitor='val_FeatRecLoss', verbose=1, save_best_only=True )\n",
    "\n",
    "SigBandRepModel.fit(DATA[:], batch_size=3500, epochs=700, shuffle=True, validation_split=0.2, callbacks=[EarlyStop,  RelLoss]) # ModelSave,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for i in range (5000):\n",
    "\n",
    "    FCs = 0.9\n",
    "    FCs = tf.clip_by_value(FCs, 1e-7, 1-1e-7)\n",
    "    Epsilon = tf.random.uniform(shape=(1, 1))\n",
    "    Epsilon = tf.clip_by_value(Epsilon, 1e-7, 1-1e-7)\n",
    "\n",
    "    LogEps = tf.math.log(Epsilon)\n",
    "    LogNegEps = tf.math.log(1 - Epsilon)\n",
    "\n",
    "    LogTheta = tf.math.log(FCs)\n",
    "    LogNegTheta = tf.math.log(1-FCs)\n",
    "\n",
    "\n",
    "    res.append(tf.math.sigmoid(LogEps - LogNegEps + LogTheta - LogNegTheta).numpy())\n",
    "    \n",
    "plt.hist(np.concatenate(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
