{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Input, GRU, Dense, Masking, Reshape, Flatten, RepeatVector, TimeDistributed, Bidirectional, Activation, GaussianNoise, Lambda, LSTM\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from Models.FeatExtModels_NoKaiser import *\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = np.load('./Data/AsanTRSet.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Env setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './Results/'\n",
    "if not os.path.exists(save_path):\n",
    "    os.mkdir(save_path)\n",
    "    \n",
    "### Model checkpoint\n",
    "ModelSaveSameName = save_path+'SigBandRepModel_DyLoss.hdf5'\n",
    "ModelSave = ModelCheckpoint(filepath=ModelSaveSameName, monitor='val_mse', verbose=1, save_best_only=True )\n",
    "\n",
    "### Model Early stop\n",
    "EarlyStop = EarlyStopping(monitor='val_loss', patience=500)\n",
    "\n",
    "LatDim = 3\n",
    "SigDim = DATA.shape[1]\n",
    "MaskingRate = 0.02\n",
    "NoiseStd = 0.002\n",
    "MaskStd = 0.1\n",
    "ReparaStd = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "class RelLossWeight(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, LossName1, LossName2, BetaName1, BetaName2, verbose=1):\n",
    "                \n",
    "        self.LossName1 = LossName1\n",
    "        self.LossName2 = LossName2\n",
    "        self.BetaName1 = BetaName1\n",
    "        self.BetaName2 = BetaName2\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        Loss1 = logs[self.LossName1] \n",
    "        Loss2 = logs[self.LossName2] \n",
    "        \n",
    "        Beta1_idx = [num for num, i in enumerate(self.model.variables) if self.BetaName1 in i.name][0]\n",
    "        Beta2_idx = [num for num, i in enumerate(self.model.variables) if self.BetaName2 in i.name][0]\n",
    "        \n",
    "        self.model.variables[Beta1_idx].assign(Loss1/Loss2)\n",
    "        self.model.variables[Beta2_idx].assign(Loss2/Loss1)   \n",
    "\n",
    "        if self.verbose==1:\n",
    "            print(self.BetaName1+' : ', self.model.variables[Beta1_idx])\n",
    "            print(self.BetaName2+' : ', self.model.variables[Beta2_idx])        \n",
    " \n",
    "\n",
    "# Define the KL annealing callback function\n",
    "class KLCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, TargetLossName, Threshold, MaxBeta, BetaName, AnnealEpoch=100):\n",
    "        self.TargetLossName = TargetLossName\n",
    "        self.Threshold = Threshold\n",
    "        self.BetaName = BetaName\n",
    "        self.MaxBeta = MaxBeta\n",
    "        self.AnnealStart = 0\n",
    "        self.AnnealEpoch = AnnealEpoch\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        TargetLoss = logs['val_'+self.TargetLossName]\n",
    "        \n",
    "        if TargetLoss > self.Threshold:\n",
    "            \n",
    "            self.AnnealStart = 0\n",
    "            K.set_value(self.model.get_layer(self.BetaName).variables[0], 0.)\n",
    "        else: \n",
    "            self.AnnealStart += 1\n",
    "            Beta = (self.AnnealStart) / self.AnnealEpoch * self.MaxBeta\n",
    "            K.set_value(self.model.get_layer(self.BetaName).variables[0], Beta)\n",
    "        \n",
    "        print(self.model.get_layer(self.BetaName).variables[0])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ParaFilters (layer, name=''):\n",
    "    Fc = Dense(1, activation='sigmoid')(layer)\n",
    "    Fc = tf.clip_by_value(Fc, 1e-7, 1-1e-7)\n",
    "    \n",
    "    # Reparameterization Trick for sampling from Uniformly distribution; ϵ∼U(0,1) \n",
    "    Epsilon = tf.random.uniform(shape=(tf.shape(Fc)[0], Fc.shape[1]))\n",
    "    Epsilon = tf.clip_by_value(Epsilon, 1e-7, 1-1e-7)\n",
    "\n",
    "    LogEps = tf.math.log(Epsilon)\n",
    "    LogNegEps = tf.math.log(1 - Epsilon)\n",
    "    \n",
    "    LogTheta = tf.math.log(Fc)\n",
    "    LogNegTheta = tf.math.log(1-Fc)\n",
    "\n",
    "    Fc = tf.math.sigmoid(LogEps - LogNegEps + LogTheta - LogNegTheta)\n",
    "    Fc = tf.clip_by_value(Fc, 1e-7, 1-1e-7)\n",
    "    Fc = ReName(Fc, name)\n",
    "    \n",
    "    return Fc \n",
    "\n",
    "\n",
    "class Lossweight(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, name='Lossweight'):\n",
    "        super(Lossweight, self).__init__(name=name)\n",
    "        pass\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.GenVec = tf.Variable(0., trainable=False)\n",
    "    \n",
    "    def call(self, input):\n",
    "\n",
    "        return self.GenVec\n",
    "    \n",
    "\n",
    "class RandFCs(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, ):\n",
    "        super(RandFCs, self).__init__(name='FCs')\n",
    "        pass\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.GenVec = tf.Variable(tf.random.uniform(shape=(1,6)), trainable=False)\n",
    "    \n",
    "    def call(self, input):\n",
    "        return tf.tile(self.GenVec , (tf.shape(input)[0],1))\n",
    "    \n",
    "\n",
    "\n",
    "class KLAnneal(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, TargetLossName, Threshold, MaxBeta, BetaName, AnnealEpoch=100, verbose=1):\n",
    "        \n",
    "        if type(TargetLossName) != list:\n",
    "            TargetLossName = [TargetLossName]\n",
    "        \n",
    "        self.TargetLossName = TargetLossName\n",
    "        self.Threshold = Threshold\n",
    "        self.BetaName = BetaName\n",
    "        self.MaxBeta = MaxBeta\n",
    "        self.AnnealStart = 0\n",
    "        self.AnnealEpoch = AnnealEpoch\n",
    "        self.verbose = verbose \n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        TargetLoss = max([logs[i] for i in self.TargetLossName]) \n",
    "        \n",
    "        if TargetLoss > self.Threshold:\n",
    "            \n",
    "            self.AnnealStart = 0\n",
    "            K.set_value(self.model.get_layer(self.BetaName).variables[0], 0.)\n",
    "        else: \n",
    "            self.AnnealStart += 1\n",
    "            Beta = (self.AnnealStart) / self.AnnealEpoch * self.MaxBeta\n",
    "            K.set_value(self.model.get_layer(self.BetaName).variables[0], Beta)\n",
    "        \n",
    "        if self.verbose==1:\n",
    "            print(self.BetaName+' : ' ,self.model.get_layer(self.BetaName).variables[0].numpy())\n",
    "        elif self.verbose==2:\n",
    "            print('TargetLoss : ', TargetLoss)\n",
    "            print(self.BetaName+' : ' ,self.model.get_layer(self.BetaName).variables[0].numpy())\n",
    "            \n",
    "            \n",
    "       \n",
    "class RelLossWeight(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, LossName1, LossName2, Beta1, Beta2, Weight =1., BetaName1 ='Beta1' , BetaName2 ='Beta2' , verbose=1):\n",
    "                \n",
    "        self.LossName1 = LossName1\n",
    "        self.LossName2 = LossName2\n",
    "        self.Beta1 = Beta1\n",
    "        self.Beta2 = Beta2\n",
    "        self.BetaName1 = BetaName1\n",
    "        self.BetaName2 = BetaName2\n",
    "        self.verbose = verbose\n",
    "        self.Weight = Weight\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        Loss1 = logs[self.LossName1] \n",
    "        Loss2 = logs[self.LossName2] \n",
    "        \n",
    "        self.Beta1.assign(self.Weight*Loss1/Loss2)\n",
    "        self.Beta2.assign(self.Weight*Loss2/Loss1)   \n",
    "\n",
    "        if self.verbose==1:\n",
    "            print(self.BetaName1+' : ', self.Beta1.numpy())\n",
    "            print(self.BetaName2+' : ', self.Beta2.numpy())   \n",
    "            \n",
    "        \n",
    "def ReName (layer, name):\n",
    "    return Lambda(lambda x: x, name=name)(layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Encoder(SigDim, LatDim= 2, Type = '', MaskingRate = 0.025, NoiseStd = 0.002, MaskStd = 0.1, ReparaStd = 0.1 , Reparam = False):\n",
    "\n",
    "    InpL = Input(shape=(SigDim,))\n",
    "    InpFrame = tf.signal.frame(InpL, 100, 100)\n",
    "\n",
    "    if Reparam:\n",
    "        InpRegul = GaussianNoise(stddev=NoiseStd)(InpFrame, training=Reparam)\n",
    "        MaskVec, NoisVec = MaskingGen(InpRegul, MaskingRate, MaskStd)\n",
    "        EncInp = Masking(mask_value=0.)(InpRegul * MaskVec )\n",
    "        EncOut = InpRegul + NoisVec\n",
    "    else:\n",
    "        EncInp, EncOut = InpFrame, InpFrame\n",
    "\n",
    "    Encoder = Dense(50, activation='relu')(InpFrame)\n",
    "    Encoder = Bidirectional(GRU(30, return_sequences=True))(Encoder)\n",
    "    Encoder = Bidirectional(GRU(30, return_sequences=False))(Encoder)\n",
    "    Encoder = Dense(50, activation='relu')(Encoder)\n",
    "    Encoder = Dense(30, activation='relu')(Encoder)\n",
    "    Encoder = Dense(15, activation='relu')(Encoder)\n",
    "\n",
    "    Z_Mean = Dense(LatDim, activation='linear')(Encoder)\n",
    "    Z_Log_Sigma = Dense(LatDim, activation='relu')(Encoder)\n",
    "    Z_Log_Sigma = ReName(Z_Log_Sigma,'Z_Log_Sigma_'+Type)\n",
    "\n",
    "    \n",
    "    # Reparameterization Trick for sampling from Guassian distribution\n",
    "    Epsilon = tf.random.normal(shape=(tf.shape(Z_Mean)[0], Z_Mean.shape[1]), mean=0., stddev=ReparaStd)\n",
    "\n",
    "    if Reparam==False:\n",
    "        Epsilon = Epsilon * 0\n",
    "\n",
    "    Z_Mean = Z_Mean + tf.exp(0.5 * Z_Log_Sigma) * Epsilon\n",
    "    Z_Mean = ReName(Z_Mean,'Z_Mean_'+Type)\n",
    "    \n",
    "    FCs =   Dense(6, activation='relu')(Z_Mean)\n",
    "    FCs =   Dense(6, activation='sigmoid')(FCs)\n",
    "    \n",
    "    \n",
    "    # Reparameterization Trick for sampling from Uniformly distribution; ϵ∼U(0,1) \n",
    "    FCs = tf.clip_by_value(FCs, 1e-7, 1-1e-7)\n",
    "    Epsilon = tf.random.uniform(shape=(tf.shape(FCs)[0], FCs.shape[1]))\n",
    "    Epsilon = tf.clip_by_value(Epsilon, 1e-7, 1-1e-7)\n",
    "    \n",
    "    LogEps = tf.math.log(Epsilon)\n",
    "    LogNegEps = tf.math.log(1 - Epsilon)\n",
    "    \n",
    "    LogTheta = tf.math.log(FCs)\n",
    "    LogNegTheta = tf.math.log(1-FCs)\n",
    "    \n",
    "    \n",
    "    FCs = tf.math.sigmoid(LogEps - LogNegEps + LogTheta - LogNegTheta)\n",
    "    FCs = tf.clip_by_value(FCs, 1e-7, 1-1e-7)\n",
    "    FCs = ReName(FCs, 'FCs')\n",
    "    \n",
    "    return [InpL], [Flatten()(EncOut), Z_Mean, FCs]\n",
    "\n",
    "\n",
    "\n",
    "def FeatExtractor(Inps, LatDim= 2, FiltLenList = [301, 301, 301, 301, 301, 301] ):\n",
    "    \n",
    "    EncReInp, InpZ, FCs = Inps\n",
    "    \n",
    "    H_F, L_F, HH_F, HL_F, LH_F, LL_F = tf.split(FCs, 6, axis=1)\n",
    "    \n",
    "\n",
    "    ### Filtering level 1 -------------------------------------------------------------------\n",
    "    ## Filter generation\n",
    "    To_H = GenHighFilter(H_F,  N=FiltLenList[0])\n",
    "    To_L = GenLowFilter(L_F, N=FiltLenList[1])\n",
    "\n",
    "    ## Perform signal filtering level 1\n",
    "    InpFrame =  tf.signal.frame(EncReInp, To_H.shape[-1], 1)\n",
    "    Sig_H = tf.reduce_sum(InpFrame*To_H[:,:,::-1], axis=-1, keepdims=True)\n",
    "    Sig_H = ReName(Sig_H, 'Sig_H_Ext')\n",
    "\n",
    "    InpFrame =  tf.signal.frame(EncReInp, To_L.shape[-1], 1)\n",
    "    Sig_L = tf.reduce_sum(InpFrame*To_L[:,:,::-1], axis=-1, keepdims=True)\n",
    "    Sig_L = ReName(Sig_L, 'Sig_L_Ext')\n",
    "\n",
    "\n",
    "\n",
    "    ### Filtering level HH and HL (from Sig_H) -------------------------------------------------------------------\n",
    "    ## Filter generation\n",
    "    To_HH = GenHighFilter(HH_F, N=FiltLenList[2])\n",
    "    To_HL = GenLowFilter(HL_F, N=FiltLenList[3])\n",
    "\n",
    "    ## Perform signal filtering level 2\n",
    "    Frame_H =  tf.signal.frame(Sig_H[:,:,0], To_HH.shape[-1], 1)\n",
    "    Sig_HH = tf.reduce_sum(Frame_H*To_HH[:,:,::-1], axis=-1, keepdims=True)\n",
    "    Sig_HH = ReName(Sig_HH, 'Sig_HH_Ext')\n",
    "\n",
    "    Frame_H =  tf.signal.frame(Sig_H[:,:,0], To_HL.shape[-1], 1)\n",
    "    Sig_HL = tf.reduce_sum(Frame_H*To_HL[:,:,::-1], axis=-1, keepdims=True)\n",
    "    Sig_HL = ReName(Sig_HL, 'Sig_HL_Ext')\n",
    "\n",
    "\n",
    "    ### Filtering level LH and LL (from Sig_L) -------------------------------------------------------------------\n",
    "    ## Filter generation\n",
    "    To_LH = GenHighFilter(LH_F,  N=FiltLenList[4])\n",
    "    To_LL = GenLowFilter(LL_F,  N=FiltLenList[5])\n",
    "\n",
    "    ## Perform signal filtering level 2\n",
    "    Frame_L =  tf.signal.frame(Sig_L[:,:,0], To_LH.shape[-1], 1)\n",
    "    Sig_LH = tf.reduce_sum(Frame_L*To_LH[:,:,::-1], axis=-1, keepdims=True)\n",
    "    Sig_LH = ReName(Sig_LH, 'Sig_LH_Ext')\n",
    "\n",
    "    Frame_L =  tf.signal.frame(Sig_L[:,:,0], To_LL.shape[-1], 1)\n",
    "    Sig_LL = tf.reduce_sum(Frame_L*To_LL[:,:,::-1], axis=-1, keepdims=True)\n",
    "    Sig_LL = ReName(Sig_LL, 'Sig_LL_Ext')\n",
    "\n",
    "    \n",
    "    return [Flatten()(Sig_HH), Flatten()(Sig_HL), Flatten()(Sig_LH), Flatten()(Sig_LL)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def FeatGenerator (Inp_lat):\n",
    "    \n",
    "    Inp_lat = tf.concat(Inp_lat, axis=-1)\n",
    "   \n",
    "    Dec_Sig_HH = Dense(10, activation='relu')(Inp_lat)\n",
    "    Dec_Sig_HH = Dense(20, activation='relu')(Dec_Sig_HH)\n",
    "    Dec_Sig_HH = Dense(30, activation='relu')(Dec_Sig_HH)\n",
    "    Dec_Sig_HH = Dense(50, activation='relu')(Dec_Sig_HH)\n",
    "\n",
    "    Dec_Sig_HH = RepeatVector(10 )(Dec_Sig_HH)\n",
    "    Dec_Sig_HH = Bidirectional(GRU(10, return_sequences=True))(Dec_Sig_HH)\n",
    "    Dec_Sig_HH = Bidirectional(GRU(20, return_sequences=True))(Dec_Sig_HH)\n",
    "    Dec_Sig_HH = Dense(40,'tanh')(Dec_Sig_HH)\n",
    "    Sig_HH= Flatten(name='Sig_HH_Gen')(Dec_Sig_HH)\n",
    "    \n",
    "    # ---------------------------------------------------------------------- #\n",
    "    \n",
    "    Dec_Sig_HL = Dense(10, activation='relu')(Inp_lat)\n",
    "    Dec_Sig_HL = Dense(20, activation='relu')(Dec_Sig_HL)\n",
    "    Dec_Sig_HL = Dense(30, activation='relu')(Dec_Sig_HL)\n",
    "    Dec_Sig_HL = Dense(50, activation='relu')(Dec_Sig_HL)\n",
    "\n",
    "    Dec_Sig_HL = RepeatVector(10 )(Dec_Sig_HL)\n",
    "    Dec_Sig_HL = Bidirectional(GRU(10, return_sequences=True))(Dec_Sig_HL)\n",
    "    Dec_Sig_HL = Bidirectional(GRU(20, return_sequences=True))(Dec_Sig_HL)\n",
    "    Dec_Sig_HL = Dense(40,'tanh')(Dec_Sig_HL)\n",
    "    Sig_HL= Flatten(name='Sig_HL_Gen')(Dec_Sig_HL)\n",
    "    \n",
    "    # ---------------------------------------------------------------------- #\n",
    "    \n",
    "    Dec_Sig_LH = Dense(10, activation='relu')(Inp_lat)\n",
    "    Dec_Sig_LH = Dense(20, activation='relu')(Dec_Sig_LH)\n",
    "    Dec_Sig_LH = Dense(30, activation='relu')(Dec_Sig_LH)\n",
    "    Dec_Sig_LH = Dense(50, activation='relu')(Dec_Sig_LH)\n",
    "\n",
    "    Dec_Sig_LH = RepeatVector(10 )(Dec_Sig_LH)\n",
    "    Dec_Sig_LH = Bidirectional(GRU(10, return_sequences=True))(Dec_Sig_LH)\n",
    "    Dec_Sig_LH = Bidirectional(GRU(20, return_sequences=True))(Dec_Sig_LH)\n",
    "    Dec_Sig_LH = Dense(40,'tanh')(Dec_Sig_LH)\n",
    "    Sig_LH= Flatten(name='Sig_LH_Gen')(Dec_Sig_LH)\n",
    "    \n",
    "    # ---------------------------------------------------------------------- #\n",
    "    \n",
    "    Dec_Sig_LL = Dense(10, activation='relu')(Inp_lat)\n",
    "    Dec_Sig_LL = Dense(20, activation='relu')(Dec_Sig_LL)\n",
    "    Dec_Sig_LL = Dense(30, activation='relu')(Dec_Sig_LL)\n",
    "    Dec_Sig_LL = Dense(50, activation='relu')(Dec_Sig_LL)\n",
    "\n",
    "    Dec_Sig_LL = RepeatVector(10 )(Dec_Sig_LL)\n",
    "    Dec_Sig_LL = Bidirectional(GRU(10, return_sequences=True))(Dec_Sig_LL)\n",
    "    Dec_Sig_LL = Bidirectional(GRU(20, return_sequences=True))(Dec_Sig_LL)\n",
    "    Dec_Sig_LL = Dense(40,'tanh')(Dec_Sig_LL)\n",
    "    Sig_LL= Flatten(name='Sig_LL_Gen')(Dec_Sig_LL)\n",
    "    \n",
    "    return  Sig_HH, Sig_HL, Sig_LH, Sig_LL\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def Reconstructor(Inps ):\n",
    "    Sigs, FCs = Inps\n",
    "    Sig_HH, Sig_HL, Sig_LH, Sig_LL = Sigs\n",
    "\n",
    "    ## GRU NET -------------------------------------------------------------------\n",
    "    Dec_Sig_HH = Reshape((-1, 100))(Sig_HH)\n",
    "    Dec_Sig_HL = Reshape((-1, 100))(Sig_HL)\n",
    "    Dec_Sig_LH = Reshape((-1, 100))(Sig_LH)\n",
    "    Dec_Sig_LL = Reshape((-1, 100))(Sig_LL)\n",
    "\n",
    "    Dec_Sig_HH = Bidirectional(GRU(5), name='Dec_Sig_HH')(Dec_Sig_HH)\n",
    "    Dec_Sig_HL = Bidirectional(GRU(5), name='Dec_Sig_HL')(Dec_Sig_HL)\n",
    "    Dec_Sig_LH = Bidirectional(GRU(5), name='Dec_Sig_LH')(Dec_Sig_LH)\n",
    "    Dec_Sig_LL = Bidirectional(GRU(5), name='Dec_Sig_LL')(Dec_Sig_LL)\n",
    "\n",
    "    Decoder = tf.concat([ Dec_Sig_HH, Dec_Sig_HL, Dec_Sig_LH, Dec_Sig_LL, FCs], axis=1)\n",
    "    Decoder = RepeatVector((SigDim//100) )(Decoder)\n",
    "    Decoder = Bidirectional(GRU(50, return_sequences=True))(Decoder)\n",
    "    Decoder = Dense(100, activation='relu')(Decoder)\n",
    "    DecOut = Dense(100, activation='sigmoid')(Decoder)\n",
    "    DecOut = Reshape((SigDim,),name='Out')(DecOut)\n",
    "\n",
    "    \n",
    "    return DecOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Encoder - FeatExtractor\n",
    "EncInp, EncOut = Encoder(SigDim=SigDim, LatDim= LatDim, Type = 'Tr', MaskingRate = MaskingRate, NoiseStd = NoiseStd, MaskStd = MaskStd, ReparaStd = ReparaStd, Reparam=True)\n",
    "FeatExtOut = FeatExtractor(EncOut)\n",
    "\n",
    "### Encoder - FeatGenerator - Reconstruction\n",
    "FeatGenOut = FeatGenerator(EncOut[1:])\n",
    "FeatGenOut = ReName(FeatGenOut, 'FeatGenOut')\n",
    "\n",
    "ReconOut = Reconstructor([FeatGenOut, EncOut[2]])\n",
    "ReconOut = ReName(ReconOut, 'ReconOut')\n",
    "\n",
    "### Define the total model\n",
    "SigBandRepModel = Model(EncInp, ReconOut)\n",
    "\n",
    "SigBandRepModel.add_weight(initializer=tf.constant_initializer(value=1.0), name='Beta_Rec', trainable=False)\n",
    "SigBandRepModel.add_weight(initializer=tf.constant_initializer(value=1.0), name='Beta_Feat', trainable=False)\n",
    "Beta_Rec = [i for i in SigBandRepModel.variables if 'Beta_Rec' in i.name][0]\n",
    "Beta_Feat = [i for i in SigBandRepModel.variables if 'Beta_Feat' in i.name][0]\n",
    "\n",
    "\n",
    "### Weight controller; Apply beta and capacity \n",
    "Capacity = 0.1 # 0.1 0.05\n",
    "Beta_Z = Lossweight(name='Beta_Z')(FeatGenOut)\n",
    "Beta_Fc = Lossweight(name='Beta_Fc')(FeatGenOut)\n",
    "\n",
    "\n",
    "### Custom loss for Reconstruction\n",
    "def RECMSE (y_true, y_pred):\n",
    "    \n",
    "    RecMSE = tf.losses.mse(y_true, y_pred)\n",
    "    RecMSE *= Beta_Rec\n",
    "    \n",
    "    return RecMSE\n",
    "\n",
    "\n",
    "### Adding the FeatRecLoss; It allows connection between the extractor and generator\n",
    "MSE = tf.keras.losses.MeanSquaredError()\n",
    "FeatRecLoss= MSE(tf.concat(FeatGenOut, axis=-1), tf.concat(FeatExtOut, axis=-1))\n",
    "\n",
    "SigBandRepModel.add_loss(FeatRecLoss * Beta_Feat.numpy() )\n",
    "SigBandRepModel.add_metric(FeatRecLoss, 'FeatRecLoss')\n",
    "\n",
    "### KL Divergence for p(Z) vs q(Z)\n",
    "Z_Sampled, Z_Log_Sigma = SigBandRepModel.get_layer('Z_Mean_Tr').output, SigBandRepModel.get_layer('Z_Log_Sigma_Tr').output\n",
    "kl_Loss_Z = 0.5 * tf.reduce_sum( Z_Sampled**2  +  tf.exp(Z_Log_Sigma)- Z_Log_Sigma-1, axis=1)    \n",
    "kl_Loss_Z = tf.reduce_mean(kl_Loss_Z )\n",
    "kl_Loss_Z = Beta_Z * tf.abs(kl_Loss_Z - Capacity)\n",
    "\n",
    "### KL Divergence for p(FCs) vs q(FCs)\n",
    "BernP = 0.5 # hyperparameter\n",
    "FCs = SigBandRepModel.get_layer('FCs').output\n",
    "kl_Loss_FC = tf.math.log(FCs) - tf.math.log(BernP) + tf.math.log(1-FCs) - tf.math.log(1-BernP) \n",
    "kl_Loss_FC = tf.reduce_mean(-kl_Loss_FC )\n",
    "kl_Loss_FC = Beta_Fc * tf.abs(kl_Loss_FC - 0.6)\n",
    "\n",
    "SigBandRepModel.add_loss(kl_Loss_Z )\n",
    "SigBandRepModel.add_metric(kl_Loss_Z, 'kl_Loss_Z')\n",
    "\n",
    "SigBandRepModel.add_loss(kl_Loss_FC )\n",
    "SigBandRepModel.add_metric(kl_Loss_FC, 'kl_Loss_FC')\n",
    "\n",
    "\n",
    "## Model Compile\n",
    "SigBandRepModel.compile(loss='mse', optimizer='adam', metrics={\"ReconOut\":'mse'}, loss_weights=[Beta_Rec.numpy()]) \n",
    "\n",
    "### Loss and KLD_Beta controller\n",
    "KLD_Beta_Z = KLAnneal(TargetLossName=['val_FeatRecLoss', 'val_mse'], Threshold=0.0015, MaxBeta=0.5 , BetaName='Beta_Z', AnnealEpoch=500, verbose=2)\n",
    "KLD_Beta_Fc = KLAnneal(TargetLossName=['val_FeatRecLoss', 'val_mse'], Threshold=0.0015, MaxBeta=0.5 , BetaName='Beta_Fc', AnnealEpoch=500, verbose=1)\n",
    "RelLoss = RelLossWeight('val_mse', 'val_FeatRecLoss', Beta_Rec, Beta_Feat, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "1/1 [==============================] - 27s 27s/step - loss: 0.0756 - mse: 0.0492 - FeatRecLoss: 0.0265 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0664 - val_mse: 0.0198 - val_FeatRecLoss: 0.0465 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_mse improved from inf to 0.01984, saving model to ./Results\\SigBandRepModel_DyLoss.hdf5\n",
      "TargetLoss :  0.04650700464844704\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  0.42670602\n",
      "Beta2 :  2.3435338\n",
      "Epoch 2/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0732 - mse: 0.0483 - FeatRecLoss: 0.0249 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0648 - val_mse: 0.0191 - val_FeatRecLoss: 0.0456 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_mse improved from 0.01984 to 0.01913, saving model to ./Results\\SigBandRepModel_DyLoss.hdf5\n",
      "TargetLoss :  0.04563800245523453\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  0.4192241\n",
      "Beta2 :  2.385359\n",
      "Epoch 3/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0688 - mse: 0.0467 - FeatRecLoss: 0.0221 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0678 - val_mse: 0.0189 - val_FeatRecLoss: 0.0488 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_mse improved from 0.01913 to 0.01894, saving model to ./Results\\SigBandRepModel_DyLoss.hdf5\n",
      "TargetLoss :  0.048828791826963425\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  0.38797164\n",
      "Beta2 :  2.577508\n",
      "Epoch 4/700\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0667 - mse: 0.0461 - FeatRecLoss: 0.0205 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0610 - val_mse: 0.0182 - val_FeatRecLoss: 0.0427 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_mse improved from 0.01894 to 0.01824, saving model to ./Results\\SigBandRepModel_DyLoss.hdf5\n",
      "TargetLoss :  0.04274938628077507\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  0.42676458\n",
      "Beta2 :  2.3432124\n",
      "Epoch 5/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0636 - mse: 0.0436 - FeatRecLoss: 0.0199 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0606 - val_mse: 0.0186 - val_FeatRecLoss: 0.0421 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_mse did not improve from 0.01824\n",
      "TargetLoss :  0.04208504036068916\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  0.44077998\n",
      "Beta2 :  2.2687056\n",
      "Epoch 6/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0621 - mse: 0.0432 - FeatRecLoss: 0.0189 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0576 - val_mse: 0.0178 - val_FeatRecLoss: 0.0398 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00006: val_mse improved from 0.01824 to 0.01778, saving model to ./Results\\SigBandRepModel_DyLoss.hdf5\n",
      "TargetLoss :  0.039843760430812836\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  0.4461856\n",
      "Beta2 :  2.24122\n",
      "Epoch 7/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0593 - mse: 0.0415 - FeatRecLoss: 0.0179 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0527 - val_mse: 0.0167 - val_FeatRecLoss: 0.0359 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00007: val_mse improved from 0.01778 to 0.01674, saving model to ./Results\\SigBandRepModel_DyLoss.hdf5\n",
      "TargetLoss :  0.035935141146183014\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  0.46584082\n",
      "Beta2 :  2.146656\n",
      "Epoch 8/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0570 - mse: 0.0396 - FeatRecLoss: 0.0174 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0540 - val_mse: 0.0166 - val_FeatRecLoss: 0.0373 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00008: val_mse improved from 0.01674 to 0.01664, saving model to ./Results\\SigBandRepModel_DyLoss.hdf5\n",
      "TargetLoss :  0.03732860088348389\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  0.44587982\n",
      "Beta2 :  2.2427568\n",
      "Epoch 9/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0546 - mse: 0.0383 - FeatRecLoss: 0.0164 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0484 - val_mse: 0.0165 - val_FeatRecLoss: 0.0319 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00009: val_mse improved from 0.01664 to 0.01649, saving model to ./Results\\SigBandRepModel_DyLoss.hdf5\n",
      "TargetLoss :  0.03187932074069977\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  0.5171303\n",
      "Beta2 :  1.9337485\n",
      "Epoch 10/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0513 - mse: 0.0356 - FeatRecLoss: 0.0157 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0508 - val_mse: 0.0166 - val_FeatRecLoss: 0.0342 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00010: val_mse did not improve from 0.01649\n",
      "TargetLoss :  0.03415107727050781\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  0.48614138\n",
      "Beta2 :  2.0570147\n",
      "Epoch 11/700\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0473 - mse: 0.0327 - FeatRecLoss: 0.0146 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0480 - val_mse: 0.0164 - val_FeatRecLoss: 0.0316 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00011: val_mse improved from 0.01649 to 0.01641, saving model to ./Results\\SigBandRepModel_DyLoss.hdf5\n",
      "TargetLoss :  0.0315837562084198\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  0.5195374\n",
      "Beta2 :  1.9247892\n",
      "Epoch 12/700\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0473 - mse: 0.0327 - FeatRecLoss: 0.0147 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0480 - val_mse: 0.0171 - val_FeatRecLoss: 0.0309 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00012: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.030944623053073883\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  0.55123764\n",
      "Beta2 :  1.8140996\n",
      "Epoch 13/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0418 - mse: 0.0287 - FeatRecLoss: 0.0131 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0488 - val_mse: 0.0207 - val_FeatRecLoss: 0.0281 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00013: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.028089802712202072\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  0.7362411\n",
      "Beta2 :  1.3582507\n",
      "Epoch 14/700\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0388 - mse: 0.0250 - FeatRecLoss: 0.0139 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0505 - val_mse: 0.0224 - val_FeatRecLoss: 0.0281 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00014: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.028057370334863663\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  0.79867554\n",
      "Beta2 :  1.2520729\n",
      "Epoch 15/700\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0369 - mse: 0.0249 - FeatRecLoss: 0.0119 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0501 - val_mse: 0.0187 - val_FeatRecLoss: 0.0315 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00015: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.03146729990839958\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  0.59321684\n",
      "Beta2 :  1.6857243\n",
      "Epoch 16/700\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0313 - mse: 0.0193 - FeatRecLoss: 0.0120 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0564 - val_mse: 0.0322 - val_FeatRecLoss: 0.0242 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00016: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.03219851851463318\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  1.331908\n",
      "Beta2 :  0.7508026\n",
      "Epoch 17/700\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0293 - mse: 0.0188 - FeatRecLoss: 0.0104 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0541 - val_mse: 0.0310 - val_FeatRecLoss: 0.0230 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00017: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.03104870766401291\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  1.3492678\n",
      "Beta2 :  0.7411427\n",
      "Epoch 18/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0280 - mse: 0.0178 - FeatRecLoss: 0.0103 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0547 - val_mse: 0.0326 - val_FeatRecLoss: 0.0221 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00018: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.032617293298244476\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  1.4749937\n",
      "Beta2 :  0.677969\n",
      "Epoch 19/700\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0271 - mse: 0.0175 - FeatRecLoss: 0.0096 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0692 - val_mse: 0.0450 - val_FeatRecLoss: 0.0241 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00019: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.04503180831670761\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  1.8662953\n",
      "Beta2 :  0.5358209\n",
      "Epoch 20/700\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0263 - mse: 0.0168 - FeatRecLoss: 0.0094 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0495 - val_mse: 0.0298 - val_FeatRecLoss: 0.0197 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00020: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.029822001233696938\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  1.5118973\n",
      "Beta2 :  0.6614206\n",
      "Epoch 21/700\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0244 - mse: 0.0155 - FeatRecLoss: 0.0088 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0565 - val_mse: 0.0388 - val_FeatRecLoss: 0.0176 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00021: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.0388377420604229\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  2.204444\n",
      "Beta2 :  0.45362914\n",
      "Epoch 22/700\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0218 - mse: 0.0140 - FeatRecLoss: 0.0079 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0538 - val_mse: 0.0382 - val_FeatRecLoss: 0.0156 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00022: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.038177814334630966\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  2.4404001\n",
      "Beta2 :  0.40976885\n",
      "Epoch 23/700\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0186 - mse: 0.0112 - FeatRecLoss: 0.0074 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0540 - val_mse: 0.0381 - val_FeatRecLoss: 0.0159 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00023: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.038113996386528015\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  2.3950431\n",
      "Beta2 :  0.417529\n",
      "Epoch 24/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0167 - mse: 0.0101 - FeatRecLoss: 0.0066 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0524 - val_mse: 0.0358 - val_FeatRecLoss: 0.0166 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00024: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.03583286702632904\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  2.1612914\n",
      "Beta2 :  0.46268636\n",
      "Epoch 25/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0171 - mse: 0.0103 - FeatRecLoss: 0.0068 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0480 - val_mse: 0.0317 - val_FeatRecLoss: 0.0163 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00025: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.031732864677906036\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  1.9501808\n",
      "Beta2 :  0.512773\n",
      "Epoch 26/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0146 - mse: 0.0079 - FeatRecLoss: 0.0067 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0420 - val_mse: 0.0219 - val_FeatRecLoss: 0.0202 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00026: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.02185654267668724\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  1.08434\n",
      "Beta2 :  0.92222\n",
      "Epoch 27/700\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0140 - mse: 0.0087 - FeatRecLoss: 0.0053 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0479 - val_mse: 0.0339 - val_FeatRecLoss: 0.0140 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00027: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.03386862203478813\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  2.4217165\n",
      "Beta2 :  0.41293025\n",
      "Epoch 28/700\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0148 - mse: 0.0098 - FeatRecLoss: 0.0050 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0393 - val_mse: 0.0236 - val_FeatRecLoss: 0.0157 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00028: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.02360829897224903\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  1.5030041\n",
      "Beta2 :  0.6653342\n",
      "Epoch 29/700\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0123 - mse: 0.0078 - FeatRecLoss: 0.0045 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0393 - val_mse: 0.0264 - val_FeatRecLoss: 0.0129 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00029: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.02635539323091507\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  2.0365963\n",
      "Beta2 :  0.49101534\n",
      "Epoch 30/700\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0125 - mse: 0.0082 - FeatRecLoss: 0.0044 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0370 - val_mse: 0.0169 - val_FeatRecLoss: 0.0200 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00030: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.020028207451105118\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  0.8452431\n",
      "Beta2 :  1.1830915\n",
      "Epoch 31/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0117 - mse: 0.0064 - FeatRecLoss: 0.0054 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0417 - val_mse: 0.0197 - val_FeatRecLoss: 0.0220 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00031: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.022022513672709465\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  0.8948909\n",
      "Beta2 :  1.1174546\n",
      "Epoch 32/700\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0108 - mse: 0.0068 - FeatRecLoss: 0.0040 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0455 - val_mse: 0.0332 - val_FeatRecLoss: 0.0123 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00032: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.03321405127644539\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  2.7085183\n",
      "Beta2 :  0.36920553\n",
      "Epoch 33/700\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0107 - mse: 0.0076 - FeatRecLoss: 0.0032 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0464 - val_mse: 0.0363 - val_FeatRecLoss: 0.0101 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00033: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.03632017597556114\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  3.6084385\n",
      "Beta2 :  0.2771282\n",
      "Epoch 34/700\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0096 - mse: 0.0060 - FeatRecLoss: 0.0035 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0421 - val_mse: 0.0316 - val_FeatRecLoss: 0.0105 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00034: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.031599175184965134\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  3.0049176\n",
      "Beta2 :  0.33278784\n",
      "Epoch 35/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0093 - mse: 0.0060 - FeatRecLoss: 0.0033 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0512 - val_mse: 0.0428 - val_FeatRecLoss: 0.0083 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00035: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.0428306870162487\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  5.147063\n",
      "Beta2 :  0.19428556\n",
      "Epoch 36/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0094 - mse: 0.0063 - FeatRecLoss: 0.0031 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0520 - val_mse: 0.0443 - val_FeatRecLoss: 0.0077 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00036: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.04429079592227936\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  5.735022\n",
      "Beta2 :  0.17436725\n",
      "Epoch 37/700\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0087 - mse: 0.0061 - FeatRecLoss: 0.0026 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0492 - val_mse: 0.0399 - val_FeatRecLoss: 0.0093 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00037: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.039870962500572205\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  4.2882867\n",
      "Beta2 :  0.23319337\n",
      "Epoch 38/700\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0109 - mse: 0.0082 - FeatRecLoss: 0.0027 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0478 - val_mse: 0.0376 - val_FeatRecLoss: 0.0102 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00038: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.03760218992829323\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  3.6872554\n",
      "Beta2 :  0.27120444\n",
      "Epoch 39/700\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0096 - mse: 0.0069 - FeatRecLoss: 0.0027 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0377 - val_mse: 0.0265 - val_FeatRecLoss: 0.0112 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00039: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.026514416560530663\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  2.3675902\n",
      "Beta2 :  0.42237037\n",
      "Epoch 40/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0085 - mse: 0.0058 - FeatRecLoss: 0.0027 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0500 - val_mse: 0.0436 - val_FeatRecLoss: 0.0064 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00040: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.04360780119895935\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  6.8471594\n",
      "Beta2 :  0.14604597\n",
      "Epoch 41/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0078 - mse: 0.0058 - FeatRecLoss: 0.0020 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0415 - val_mse: 0.0342 - val_FeatRecLoss: 0.0073 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00041: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.034163977950811386\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  4.6725698\n",
      "Beta2 :  0.214015\n",
      "Epoch 42/700\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0091 - mse: 0.0066 - FeatRecLoss: 0.0024 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0496 - val_mse: 0.0432 - val_FeatRecLoss: 0.0064 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00042: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.04318159073591232\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  6.7430577\n",
      "Beta2 :  0.14830066\n",
      "Epoch 43/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0080 - mse: 0.0058 - FeatRecLoss: 0.0023 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0430 - val_mse: 0.0369 - val_FeatRecLoss: 0.0060 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00043: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.03690362721681595\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  6.100371\n",
      "Beta2 :  0.16392446\n",
      "Epoch 44/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0083 - mse: 0.0062 - FeatRecLoss: 0.0021 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0355 - val_mse: 0.0287 - val_FeatRecLoss: 0.0068 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00044: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.02865237556397915\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  4.1846066\n",
      "Beta2 :  0.2389711\n",
      "Epoch 45/700\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0072 - mse: 0.0052 - FeatRecLoss: 0.0019 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0396 - val_mse: 0.0310 - val_FeatRecLoss: 0.0086 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00045: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.03098808228969574\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  3.6041758\n",
      "Beta2 :  0.27745593\n",
      "Epoch 46/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0073 - mse: 0.0048 - FeatRecLoss: 0.0025 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0331 - val_mse: 0.0210 - val_FeatRecLoss: 0.0121 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00046: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.02101876400411129\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  1.7408539\n",
      "Beta2 :  0.57443076\n",
      "Epoch 47/700\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0076 - mse: 0.0054 - FeatRecLoss: 0.0022 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0453 - val_mse: 0.0294 - val_FeatRecLoss: 0.0159 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00047: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.029436144977808\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  1.8518181\n",
      "Beta2 :  0.54000986\n",
      "Epoch 48/700\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0078 - mse: 0.0057 - FeatRecLoss: 0.0021 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0343 - val_mse: 0.0247 - val_FeatRecLoss: 0.0096 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00048: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.02467155270278454\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  2.5742714\n",
      "Beta2 :  0.3884594\n",
      "Epoch 49/700\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0078 - mse: 0.0059 - FeatRecLoss: 0.0019 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0380 - val_mse: 0.0259 - val_FeatRecLoss: 0.0121 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00049: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.025898899883031845\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  2.146254\n",
      "Beta2 :  0.46592805\n",
      "Epoch 50/700\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0076 - mse: 0.0057 - FeatRecLoss: 0.0019 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0391 - val_mse: 0.0307 - val_FeatRecLoss: 0.0084 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00050: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.030723385512828827\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  3.662129\n",
      "Beta2 :  0.2730652\n",
      "Epoch 51/700\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0087 - mse: 0.0059 - FeatRecLoss: 0.0029 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0410 - val_mse: 0.0323 - val_FeatRecLoss: 0.0087 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00051: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.03228946402668953\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  3.6989212\n",
      "Beta2 :  0.2703491\n",
      "Epoch 52/700\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0074 - mse: 0.0049 - FeatRecLoss: 0.0025 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0383 - val_mse: 0.0286 - val_FeatRecLoss: 0.0096 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00052: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.0286472886800766\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  2.9820635\n",
      "Beta2 :  0.33533826\n",
      "Epoch 53/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0072 - mse: 0.0048 - FeatRecLoss: 0.0024 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0427 - val_mse: 0.0340 - val_FeatRecLoss: 0.0087 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00053: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.03397981822490692\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  3.910066\n",
      "Beta2 :  0.25575018\n",
      "Epoch 54/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0067 - mse: 0.0047 - FeatRecLoss: 0.0020 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0457 - val_mse: 0.0398 - val_FeatRecLoss: 0.0059 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00054: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.03979506716132164\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  6.7283216\n",
      "Beta2 :  0.14862548\n",
      "Epoch 55/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0073 - mse: 0.0050 - FeatRecLoss: 0.0023 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0504 - val_mse: 0.0448 - val_FeatRecLoss: 0.0056 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00055: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.04475340247154236\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  7.9834085\n",
      "Beta2 :  0.12525979\n",
      "Epoch 56/700\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0083 - mse: 0.0061 - FeatRecLoss: 0.0022 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0429 - val_mse: 0.0362 - val_FeatRecLoss: 0.0067 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00056: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.03621942177414894\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  5.3916397\n",
      "Beta2 :  0.18547232\n",
      "Epoch 57/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0076 - mse: 0.0058 - FeatRecLoss: 0.0018 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0417 - val_mse: 0.0320 - val_FeatRecLoss: 0.0098 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00057: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.03197803720831871\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  3.2795124\n",
      "Beta2 :  0.3049234\n",
      "Epoch 58/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0082 - mse: 0.0062 - FeatRecLoss: 0.0019 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0421 - val_mse: 0.0336 - val_FeatRecLoss: 0.0085 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00058: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.033611901104450226\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  3.9513712\n",
      "Beta2 :  0.2530767\n",
      "Epoch 59/700\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0087 - mse: 0.0064 - FeatRecLoss: 0.0023 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0403 - val_mse: 0.0342 - val_FeatRecLoss: 0.0061 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00059: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.03423915058374405\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  5.617718\n",
      "Beta2 :  0.17800821\n",
      "Epoch 60/700\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0078 - mse: 0.0057 - FeatRecLoss: 0.0021 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0403 - val_mse: 0.0322 - val_FeatRecLoss: 0.0081 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00060: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.03222260996699333\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  3.9759796\n",
      "Beta2 :  0.25151035\n",
      "Epoch 61/700\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0075 - mse: 0.0057 - FeatRecLoss: 0.0019 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0320 - val_mse: 0.0211 - val_FeatRecLoss: 0.0109 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00061: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.021105004474520683\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  1.93949\n",
      "Beta2 :  0.5155995\n",
      "Epoch 62/700\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0074 - mse: 0.0053 - FeatRecLoss: 0.0021 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0313 - val_mse: 0.0208 - val_FeatRecLoss: 0.0105 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00062: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.020833702757954597\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  1.9877002\n",
      "Beta2 :  0.50309396\n",
      "Epoch 63/700\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0066 - mse: 0.0046 - FeatRecLoss: 0.0020 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0347 - val_mse: 0.0239 - val_FeatRecLoss: 0.0107 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00063: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.02391199767589569\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  2.2255769\n",
      "Beta2 :  0.44932172\n",
      "Epoch 64/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0073 - mse: 0.0056 - FeatRecLoss: 0.0016 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0321 - val_mse: 0.0228 - val_FeatRecLoss: 0.0093 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00064: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.022778121754527092\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  2.4537237\n",
      "Beta2 :  0.40754384\n",
      "Epoch 65/700\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0070 - mse: 0.0050 - FeatRecLoss: 0.0020 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0397 - val_mse: 0.0329 - val_FeatRecLoss: 0.0068 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00065: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.03290492296218872\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  4.848547\n",
      "Beta2 :  0.20624734\n",
      "Epoch 66/700\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0082 - mse: 0.0066 - FeatRecLoss: 0.0016 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0315 - val_mse: 0.0224 - val_FeatRecLoss: 0.0090 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00066: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.022446783259510994\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  2.491405\n",
      "Beta2 :  0.4013799\n",
      "Epoch 67/700\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0097 - mse: 0.0077 - FeatRecLoss: 0.0020 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0356 - val_mse: 0.0268 - val_FeatRecLoss: 0.0088 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00067: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.026794899255037308\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  3.0560482\n",
      "Beta2 :  0.32722\n",
      "Epoch 68/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0062 - mse: 0.0046 - FeatRecLoss: 0.0017 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0386 - val_mse: 0.0292 - val_FeatRecLoss: 0.0094 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00068: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.029159778729081154\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  3.0870547\n",
      "Beta2 :  0.32393333\n",
      "Epoch 69/700\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0069 - mse: 0.0051 - FeatRecLoss: 0.0018 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0400 - val_mse: 0.0321 - val_FeatRecLoss: 0.0079 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00069: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.03207717835903168\n",
      "Beta_Z :  0.0\n",
      "Beta_Fc :  0.0\n",
      "Beta1 :  4.061873\n",
      "Beta2 :  0.24619184\n",
      "Epoch 70/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0070 - mse: 0.0052 - FeatRecLoss: 0.0018 - kl_Loss_Z: 0.0000e+00 - kl_Loss_FC: 0.0000e+00 - val_loss: 0.0346 - val_mse: 0.0207 - val_FeatRecLoss: 0.0139 - val_kl_Loss_Z: 0.0000e+00 - val_kl_Loss_FC: 0.0000e+00\n",
      "\n",
      "Epoch 00070: val_mse did not improve from 0.01641\n",
      "TargetLoss :  0.02067253738641739\n",
      "Beta_Z :  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SigBandRepModel.load_weights(ModelSaveSameName)\n",
    "SigBandRepModel.fit(DATA[:], DATA[:], batch_size=3500, epochs=700, shuffle=True, validation_split=0.2, callbacks=[EarlyStop, ModelSave, KLD_Beta_Z, KLD_Beta_Fc, RelLoss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
